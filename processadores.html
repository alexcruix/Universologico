<!DOCTYPE html><!-- HTML5 -->
<html prefix="og: http://ogp.me/ns#" lang="pt-BR" dir="ltr">
	<head>
		<title>Processadores - Universo de Tecnologia</title>
		<meta charset="utf-8" />
		<!--[if IE]><meta http-equiv="ImageToolbar" content="False" /><![endif]-->
		<meta name="author" content="Alex de Campos Santos" />
		<meta name="generator" content="Incomedia WebSite X5 Pro 2020.1.8 - www.websitex5.com" />
		<meta name="description" content="Funcionamento de um processador!!" />
		<meta property="og:locale" content="br" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="http://192.168.42.178:8080/processadores.html" />
		<meta property="og:title" content="Processadores" />
		<meta property="og:site_name" content="Universo de Tecnologia" />
		<meta property="og:description" content="Funcionamento de um processador!!" />
		<meta property="og:image" content="http://192.168.42.178:8080/favImage.png" />
		<meta property="og:image:type" content="image/png">
		<meta property="og:image:width" content="303">
		<meta property="og:image:height" content="303">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link rel="stylesheet" href="style/reset.css?2020-1-8-1" media="screen,print" />
		<link rel="stylesheet" href="style/print.css?2020-1-8-1" media="print" />
		<link rel="stylesheet" href="style/style.css?2020-1-8-1" media="screen,print" />
		<link rel="stylesheet" href="style/template.css?2020-1-8-1" media="screen" />
		<link rel="stylesheet" href="appsresources/css/style_ezjpbkhj.css" media="screen, print" />
		<link rel="stylesheet" href="pluginAppObj/pluginAppObj_297_01/css/custom.css" media="screen, print" />
		<style>
#google_translate_element{
overflow: auto;
}
.goog-te-menu-frame {
max-width:100% !important;
box-shadow: none !important;
}
</style>
<style id='gt-style'></style><link rel="stylesheet" href="appsresources/snowfall.css" media="screen, print" />
		<link rel="stylesheet" href="pcss/processadores.css?2020-1-8-1-637248675595384965" media="screen,print" />
		<script src="res/jquery.js?2020-1-8-1"></script>
		<script src="res/x5engine.js?2020-1-8-1" data-files-version="2020-1-8-1"></script>
		<script src="res/x5engine.offline.js?2020-1-8-1-637248675591984203"></script>
		<script src="appsresources/js/main_aw6gkrc7.js"></script>
		<script src="appsresources/snowfall.js"></script>
		<script>
			window.onload = function(){ checkBrowserCompatibility('Seu navegador não suporta os recursos necessários para exibir este website.','Seu navegador pode não ser compatível com as funcionalidades necessárias para exibir este website.','[1]Atualizar seu navegador[/1] ou [2]continuar sem atualizar[/2].','http://outdatedbrowser.com/'); };
			x5engine.utils.currentPagePath = 'processadores.html';
			x5engine.boot.push(function () { x5engine.utils.imCodeProtection('Alex de Campos Santos'); });
			x5engine.boot.push(function () { x5engine.imPageToTop.initializeButton({}); });
		</script>
		<link rel="icon" href="favicon.png?2020-1-8-1-637248675592614339" type="image/png" />
		<script data-ad-client="ca-pub-6455275542096466" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
		<script>x5engine.boot.push(function () {x5engine.analytics.setPageView({ "postUrl": "analytics/wsx5analytics.php" });});</script>

	</head>
	<body>
		<div id="imPageExtContainer">
			<div id="imPageIntContainer">
				<div id="imHeaderBg"></div>
				<div id="imFooterBg"></div>
				<div id="imPage">
					<header id="imHeader">
						<h1 class="imHidden">Processadores - Universo de Tecnologia</h1>
						<div id="imHeaderObjects"><div id="imHeader_pluginAppObj_08_wrapper" class="template-object-wrapper"><!-- Google Translate v.9 --><div id="imHeader_pluginAppObj_08">

      <div id="google_translate_element"></div>

      <script>
         function googleTranslateElementInit() {
           new google.translate.TranslateElement({
             pageLanguage: 'pt',
             autoDisplay: false,
             layout: google.translate.TranslateElement.InlineLayout.SIMPLE
           }, 'google_translate_element');
         }

         function changeGoogleStyles() {
            if(($goog = $('.goog-te-menu-frame').contents().find('head')).length) {
               var stylesHtml = '<style>.goog-te-menu2 { max-width: 100% !important; overflow: scroll !important; box-sizing:border-box !important; height:auto !important; }</style>';
               if($goog.html().indexOf(stylesHtml) == -1){
                  $goog.append(stylesHtml);
               }
               $("#gt-style").empty().append(".goog-te-menu-frame{width: " + $("#imPage").width() + "px !important;}");
            } else {
               setTimeout(changeGoogleStyles, 200);
            }
         }
         changeGoogleStyles();

         $(window).on('resize', function(){
            changeGoogleStyles();
         });
      </script>
      <script src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
   </div></div><div id="imHeader_imObjectImage_09_wrapper" class="template-object-wrapper"><div id="imHeader_imObjectImage_09"><div id="imHeader_imObjectImage_09_container"></div></div>
<script>
	x5engine.boot.push(function () {
		$('#imHeader_imObjectImage_09').addClass('imlazyloading').trigger('imLazyLoadingStart');
		new x5engine.mediaObject({
			'url': '211206165160216183098173198155161096157152214166099207227213',
			'protect': true,
			'load': function ( o ) {
				$('#imHeader_imObjectImage_09_container').html( $(o.DOMObject()).css({ 'position': 'relative', 'left': 0, 'top': 0 }) );
				$('#imHeader_imObjectImage_09').trigger('imLazyLoadingEnd');
			}
		});
	});
</script>
</div><div id="imHeader_pluginAppObj_12_wrapper" class="template-object-wrapper"><!-- SnowFall v.2 --><div id="imHeader_pluginAppObj_12">
        <script>
            
            if(isEnabled()){
                var obj = document.createElement('div');
                obj.style.position = 'fixed';
                obj.style.left = '0px';
                obj.style.top = '0px';
                obj.style.width = '100%';
                obj.style.height = '100%';
                obj.style.zIndex = 999999;
                obj.style.pointerEvents = 'none';
                obj.className = 'imHeader_pluginAppObj_12 flake-container';
                document.body.insertBefore(obj, document.body.firstChild);
                snowFall.snow(obj, {
                    round: true,
                    shadow: false,
                    flakeColor: '#f8f8ff',
                    flakePosition: 'fixed',
                    flakeIndex: 999999,
                    flakeCount: 20,
                    minSize: 5 * 1,
                    maxSize: 10 * 1,
                    minSpeed: 1,
                    maxSpeed: 3,
                    image: "pluginAppObj/imHeader_pluginAppObj_12/snowflake3.png"
                });
            }
            function isEnabled(){
                var start = date(6, 21);
				var end =  date(9, 22);
				var now = new Date();
				var today = date(now.getMonth() + 1, now.getDate());
				if(start.isBefore(end)) {
					return start.isBefore(today) && today.isBefore(end);
				} else {
					return start.isBefore(today) || today.isBefore(end);
				}

				function date(month, day){
					var obj = {
						m : month,
						d : day,
						isBefore : function(date){
							return this.m < date.m || (this.m === date.m && this.d <= date.d);
						}
					};
					return obj;
				}

            }
        </script>
        </div></div><div id="imHeader_imObjectImage_15_wrapper" class="template-object-wrapper"><div id="imHeader_imObjectImage_15"><div id="imHeader_imObjectImage_15_container"><a href="index.html" onclick="return x5engine.utils.location('index.html', null, false)"><img src="images/unnamed--1-.png" title="" alt="" />
</a>
<script>
	x5engine.boot.push(function () {
		 x5engine.imagefx.glow('#imHeader_imObjectImage_15_container img', 10, 'rgba(0, 0, 255, 1)');
	});
</script>
</div></div></div><div id="imHeader_imObjectImage_16_wrapper" class="template-object-wrapper"><div id="imHeader_imObjectImage_16"><div id="imHeader_imObjectImage_16_container"><a href="pagina-inicial---mobile.html" onclick="return x5engine.utils.location('pagina-inicial---mobile.html', null, false)"><img src="images/146-1461289_clip-art-celular-desenho-celular-desenho-png-transparent.png" title="" alt="" />
</a>
<script>
	x5engine.boot.push(function () {
		 x5engine.imagefx.glow('#imHeader_imObjectImage_16_container img', 10, 'rgba(0, 0, 255, 1)');
	});
</script>
</div></div></div></div>
					</header>
					<div id="imStickyBarContainer">
						<div id="imStickyBarGraphics"></div>
						<div id="imStickyBar">
							<div id="imStickyBarObjects"><div id="imStickyBar_imMenuObject_03_wrapper" class="template-object-wrapper"><!-- UNSEARCHABLE --><div id="imStickyBar_imMenuObject_03"><div id="imStickyBar_imMenuObject_03_container"><div class="hamburger-button hamburger-component"><div><div><div class="hamburger-bar"></div><div class="hamburger-bar"></div><div class="hamburger-bar"></div></div></div></div><div class="hamburger-menu-background-container hamburger-component">
	<div class="hamburger-menu-background menu-mobile menu-mobile-animated hidden">
		<div class="hamburger-menu-close-button"><span>&times;</span></div>
	</div>
</div>
<ul class="menu-mobile-animated hidden">
	</ul></div></div><!-- UNSEARCHABLE END --><script>
var imStickyBar_imMenuObject_03_settings = {
	'menuId': 'imStickyBar_imMenuObject_03',
	'responsiveMenuEffect': 'slide',
	'animationDuration': 1000,
}
x5engine.boot.push(function(){x5engine.initMenu(imStickyBar_imMenuObject_03_settings)});
$(function () {$('#imStickyBar_imMenuObject_03_container ul li').not('.imMnMnSeparator').each(function () {    var $this = $(this), timeout = 0, subtimeout = 0, width = 'none', height = 'none';        var submenu = $this.children('ul').add($this.find('.multiple-column > ul'));    $this.on('mouseenter', function () {        if($(this).parents('#imStickyBar_imMenuObject_03_container-menu-opened').length > 0) return;         clearTimeout(timeout);        clearTimeout(subtimeout);        $this.children('.multiple-column').show(0);        submenu.stop(false, false);        if (width == 'none') {             width = submenu.width();        }        if (height == 'none') {            height = submenu.height();            submenu.css({ overflow : 'hidden', height: 0});        }        setTimeout(function () {         submenu.css({ overflow : 'hidden'}).fadeIn(1).animate({ height: height }, 300, null, function() {$(this).css('overflow', 'visible'); });        }, 250);    }).on('mouseleave', function () {        if($(this).parents('#imStickyBar_imMenuObject_03_container-menu-opened').length > 0) return;         timeout = setTimeout(function () {         submenu.stop(false, false);            submenu.css('overflow', 'hidden').animate({ height: 0 }, 300, null, function() {$(this).fadeOut(0); });            subtimeout = setTimeout(function () { $this.children('.multiple-column').hide(0); }, 300);        }, 250);    });});});

</script>
</div></div>
						</div>
					</div>
					<a class="imHidden" href="#imGoToCont" title="Pular o Menu principal">Ir para o conteúdo</a>
					<div id="imSideBar">
						<div id="imSideBarObjects"><div id="imSideBar_imObjectImage_01_wrapper" class="template-object-wrapper"><div id="imSideBar_imObjectImage_01"><div id="imSideBar_imObjectImage_01_container"><img src="images/empty-GT_imagea-1-.png" title="" alt="" />
</div></div></div></div>
					</div>
					<div id="imContentGraphics"></div>
					<main id="imContent">
						<a id="imGoToCont"></a>
						<div id="imPageRow_1" class="imPageRow">
						
						</div>
						<div id="imCell_1" class=""  data-responsive-sequence-number="1"> <div id="imCellStyleGraphics_1"></div><div id="imCellStyleBorders_1"></div><!-- Animated Headlines v.17 --><div id="pluginAppObj_297_01">
						
							  <div class="cd-intro"><p class="cd-headline letters scale"><span class="cd-words-wrapper"><b class="is-visible">Processadores</b><b>Processor</b></span></p></div>
						   </div></div><div id="imPageRow_2" class="imPageRow">
						
						</div>
						<div id="imCell_2" class=""  data-responsive-sequence-number="2"> <div id="imCellStyleGraphics_2"></div><div id="imCellStyleBorders_2"></div><div id="imObjectImage_297_02"><div id="imObjectImage_297_02_container"></div></div>
						<script>
							x5engine.boot.push(function () {
								$('#imObjectImage_297_02').addClass('imlazyloading').trigger('imLazyLoadingStart');
								new x5engine.mediaObject({
									'url': '211206165160216183098174188160154162222208212095165209228209200237165203151221171179160095213194166173201111150152084128112099107146162161209',
									'protect': true,
									'load': function ( o ) {
										$('#imObjectImage_297_02_container').html( $(o.DOMObject()).css({ 'position': 'relative', 'left': 0, 'top': 0 }) );
										$('#imObjectImage_297_02').trigger('imLazyLoadingEnd');
									}
								});
							});
						</script>
						</div><div id="imPageRow_3" class="imPageRow">
						
						</div>
						<div id="imCell_3" class=""  data-responsive-sequence-number="3"> <div id="imCellStyleGraphics_3"></div><div id="imCellStyleBorders_3"></div><div id="imTextObject_297_03">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_03_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O <b>microprocessador</b>, geralmente chamado apenas de <b>processador</b>, é um circuito integrado que realiza as funções de cálculo e tomada de decisão de um computador. &nbsp;Todos os computadores e equipamentos eletrônicos baseiam-se nele para &nbsp;executar suas funções, podemos dizer que o processador é o cérebro do &nbsp;computador por realizar todas estas funções. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Um microprocessador incorpora as funções de uma unidade central de computação (UCP) &nbsp;em um único circuito integrado, ou no máximo alguns circuitos &nbsp;integrados. É um dispositivo multifuncional programável que aceita dados &nbsp;digitais como entrada, processa de acordo com as instruções armazenadas &nbsp;em sua memória, e fornece resultados como saída. Microprocessadores &nbsp;operam com números e símbolos representados no sistema binário. </span></div> <div> &nbsp;</div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Arquitetura &nbsp;interna de um microprocessador dedicado para processamento de imagens &nbsp;de ressonância magnética, a fotografia foi aumentada 600 vezes, sob luz &nbsp;ultravioleta para se enxergar os detalhes</span></div> <div> &nbsp;</div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vista inferior de um Athlon XP 1800+ núcleo Palomino, um microprocessador moderno.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O microprocessador é um circuito integrado formado por uma camada chamada de mesa epitaxial de silício, trabalhada de modo a formar um cristal &nbsp;de extrema pureza, laminada até uma espessura mínima com grande &nbsp;precisão, depois cuidadosamente mascarada por um processo fotográfico e &nbsp;dopada pela exposição a altas temperaturas em fornos que contêm misturas &nbsp;gasosas de impurezas. Este processo é repetido tantas vezes quanto &nbsp;necessário à formação da microarquitetura do componente. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Responsável pela execução das instruções num sistema, o &nbsp;microprocessador, escolhido entre os disponíveis no mercado, determina, &nbsp;em certa medida a capacidade de processamento do computador e também o conjunto primário de instruções que ele compreende. O sistema operativo é construído sobre este conjunto. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O próprio microprocessador subdivide-se em várias unidades, trabalhando em altas freqüências. A ULA (<i>Unidade Lógica e Aritmética</i>), unidade responsável pelos cálculos aritméticos e lógicos e os registradores são parte integrante do microprocessador na família x86, por exemplo. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Embora seja a essência do computador, o microprocessador diferente do microcontrolador, está longe de ser um computador completo. Para que possa interagir com o utilizador precisa de: memória, dispositivos de entrada/saída, um clock, &nbsp;controladores e conversores de sinais, entre outros. Cada um desses &nbsp;circuitos de apoio interage de modo peculiar com os programas e, dessa &nbsp;forma, ajuda a moldar o funcionamento do computador. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><div><span class="fs11lh1-5 ff1"><b>História</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Herman Hollerith, &nbsp;um inventor de diversas máquinas elétricas para a soma e contagem de &nbsp;dados que eram representados sob a forma de fitas de papel perfuradas. &nbsp;Através dessas perfurações, os dados que elas representavam podiam ser &nbsp;computados de uma forma rápida e automática, através de circuitos &nbsp;elétricos. Com esse processo, os Estados Unidos puderam acompanhar de &nbsp;perto o crescimento de sua população. Os resultados do censo de 1890 &nbsp;foram fornecidos três anos depois, economizando-se vários anos de &nbsp;trabalho. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em 1896, Hollerith criou a Tabulating Machine Company e &nbsp;introduziu inovações em sua descoberta: a fita de papel foi substituída &nbsp;por cartões. Estes viriam a ser o elemento básico das máquinas IBM de &nbsp;processamento de dados de algumas décadas atrás. Já em 1911, duas outras &nbsp;companhias, a Internacional Time Recorde Co. &nbsp;(de registradores mecânicos de tempo), e a Computing Cale Co. (de &nbsp;instrumentos de aferição de peso), uniram-se a ela, por sugestão do &nbsp;negociante e banqueiro Charles R. Flint, formando-se então a Computing Tabulating Recording Co - a CTR. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Três anos mais tarde, em 1914, Thomas J. Watson &nbsp;(líder industrial que foi um dos homens mais ricos do seu tempo) &nbsp;assumiu a presidência da organização e estabeleceu normas de trabalho &nbsp;absolutamente inovadoras para a época. Naquele tempo, a CTR contava com &nbsp;menos de 1400 funcionários e as constantes pesquisas de engenharia &nbsp;resultaram na criação e no aperfeiçoamento de novas máquinas de &nbsp;contabilidade, exigidas pelo rápido desenvolvimento industrial. Antes do &nbsp;ano de 1924, aquele pequeno grupo de homens havia aumentado e &nbsp;diversificado muito sua experiência. Os produtos ganharam maior &nbsp;qualidade, surgiram novas máquinas e com elas novos escritórios de &nbsp;vendas e mais vendedores. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em fevereiro de 1924 a CTR muda seu nome para INTERNATIONAL BUSINESS MACHINES, hoje mundialmente conhecida pelo seu acrônimo, IBM. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A sigla IBM passou a ser, desde então, a fórmula para que a &nbsp;indústria e o comércio continuassem a resolver seus problemas de &nbsp;desenvolvimento.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No início do século XX, a IBM era a única empresa do mundo que &nbsp;dispunha da tecnologia de cartões perfurados, aplicado em quase todas as &nbsp;áreas que utilizavam máquinas para cadastro, identificação, arquivo e &nbsp;regulação de informações. O equipamento desenvolvido pela IBM foi também &nbsp;utilizado para fins menos nobres durante o período da 2ª Guerra &nbsp;Mundial, quando o Terceiro Reich firmou uma parceria com a empresa para &nbsp;automatizar o sistema de identificação, controle e transferência de prisioneiros, segundo o jornalista Edwin &nbsp;Black no seu livro “Nazi Nexus: America's Corporate Connections to &nbsp;Hitler's Holocaus<i>t</i>”, de 2009. Os serviços prestados pela IBM ao &nbsp;governo alemão rendeu o equivalente a US$ 200 milhões. O número de &nbsp;identificação tatuado no braço dos prisioneiros do campo de concentração &nbsp;de Auschwitz relacionava-se ao número de cartão perfurado dos registros &nbsp;da IBM.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em consequência do constante e rápido desenvolvimento, a &nbsp;International Business Machines Corporation criou em 1949 a IBM World &nbsp;Trade Corporation, uma subsidiária inteiramente independente, cujo &nbsp;objetivo era aumentar vendas, serviços e produção fora dos Estados &nbsp;Unidos. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As fábricas e laboratórios da IBM funcionam em 15 diferentes &nbsp;países. Essas fábricas estão integradas aos laboratórios de &nbsp;desenvolvimento na França, Alemanha, Espanha, Itália, Holanda, Suécia, Inglaterra, Brasil, Argentina, Colômbia, México, Canadá, Austrália e Japão.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A IBM é uma das principais empresas que investe em pesquisa e &nbsp;desenvolvimento mantendo-se na liderança do ranking de publicação de &nbsp;patentes há 16 anos consecutivos - a IBM publicou 4.914 patentes &nbsp;norte-americanas em 2009, estabelecendo um recorde histórico para a "Big &nbsp;Blue", mantendo sua liderança contra competidores como a Samsung (3.611 patentes) e a Microsoft (2.906 patentes). </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nos últimos anos, a IBM transformou completamente seu modelo de &nbsp;negócio. A empresa se desfez de várias atividades que já tinham se &nbsp;transformado em "commodities", como os segmentos de PCs &nbsp;e impressoras, e ampliou os investimentos nas áreas de prestação de &nbsp;serviços, que possuem um superior valor agregado, como consultoria, &nbsp;informação sob demanda e serviços. Em 2005, sua divisão de PCs foi vendida para a empresa chinesa Lenovo.</span></div></div><div><span class="fs11lh1-5 ff1"><br></span></div><div class="imTACenter"><span class="fs20lh1-5 ff1"><b>Multicore</b></span></div><div class="imTACenter"><span class="fs20lh1-5 ff1"><b><br></b></span></div><div class="imTALeft"><div><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Processador multinúcleo</b> (múltiplos núcleos, do inglês <b>multicore</b>) é o que tem dois ou mais núcleos de processamento (<i>cores</i>) no interior de um único chip. Estes dois ou mais núcleos são responsáveis por dividir as tarefas entre si, ou seja, permitem trabalhar em um ambiente multitarefa. &nbsp;Em processadores de um só núcleo, as funções de multitarefa podem &nbsp;ultrapassar a capacidade da CPU, o que resulta em queda no desempenho &nbsp;enquanto as operações aguardam para serem processadas. Em processadores &nbsp;de múltiplos núcleos o sistema operacional trata cada um desses núcleos como um processador diferente. Na maioria dos casos, cada unidade possui seu próprio cache &nbsp;e pode processar várias instruções quase simultaneamente. Adicionar &nbsp;novos núcleos de processamento a um processador (único encapsulamento) &nbsp;possibilita que as instruções das aplicações sejam executadas em &nbsp;paralelo, como se fossem 2 ou mais processadores distintos. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Os dois núcleos não somam a capacidade de processamento, mas &nbsp;dividem as tarefas entre si. Por exemplo, um processador de dois núcleos &nbsp;com clock de 1.8 GHz &nbsp;não equivale a um processador de um núcleo funcionando com clock de 3.6 &nbsp;Ghz, e sim dois núcleos 1,8GHZ operando em paralelo. O termo multinúcleo ou multicore (como é popularmente conhecido), são &nbsp;por vezes utilizados para descrever arquiteturas multicore com um número &nbsp;particularmente elevado de núcleos (dezenas ou centenas). </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O surgimento dos processadores multicore, tornou-se necessário &nbsp;principalmente devido a missão cada vez mais difícil de resfriar &nbsp;processadores singlecore (processadores de apenas um núcleo) com clocks &nbsp;cada vez mais altos; devido a concentração cada vez maior de &nbsp;transistores cada vez menores em um mesmo circuito integrado. E além &nbsp;dessa e outras limitações dos processadores singlecore, existe a grande &nbsp;diferença &nbsp;entre a &nbsp;velocidade da memória e do processador, aliada à &nbsp;estreita banda de dados, que faz com que aproximadamente 75 por cento do &nbsp;uso do microprocessador seja gasto na espera por resultados dos acessos &nbsp;à memória. </div><div><br></div><div><div><span class="fs11lh1-5"><b>Descrição</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Na &nbsp;maioria dos processadores de mais de um núcleo, cada núcleo pode possuir &nbsp;sua própria cache e alguns casos realizam acesso direto e independente à &nbsp;memória principal; possibilita-se, assim, que as instruções de &nbsp;aplicações sejam executadas em paralelo, ou seja, cada processador &nbsp;realiza os cálculos de que é requisitado concorrentemente com o outro, &nbsp;ganhando desempenho. Este, porém, depende muito dos algoritmos de &nbsp;software utilizados e de suas implementações. </div><div>Outra vantagem do processamento em paralelo é a capacidade de &nbsp;cada processador ficar responsável pela execução de um aplicativo, como &nbsp;por exemplo, quando o usuário está executando algum arquivo de som e ao &nbsp;mesmo tempo executando a varredura do antivírus. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A diferença desse processamento paralelo e do até então usado nos &nbsp;processadores singlecore pode ser visto nas figuras abaixo; observe o &nbsp;gargalo (<i>bottleneck</i>) &nbsp;criado pelos aplicativos executados simultaneamente no singlecore, e &nbsp;como ele desaparece na figura com os dois núcleos (cores). </div><div><br></div> <div><span class="fs11lh1-5"><b>Surgimento</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Embora &nbsp;a tecnologia de fabricação tenha melhorado, reduzindo o tamanho de &nbsp;processadores individuais, limites físicos de semicondutores baseados em &nbsp;microeletrônica haviam se tornado uma preocupação principal. Estas &nbsp;limitações físicas poderiam causar dissipação de calor significativa e &nbsp;problemas de sincronização de dados. Vários métodos foram e estão sendo &nbsp;usados ​​para melhorar o desempenho da CPU. Alguns paralelismos por &nbsp;nível de instrução (ILP), métodos como pipelining superescalares são &nbsp;adequados para muitas aplicações, mas são ineficientes para os que são &nbsp;difíceis de prever código. Muitas aplicações são mais adequadas para &nbsp;paralelismo por nível de thread (TLP), métodos e múltiplas CPUs &nbsp;independentes são comumente usados ​​para aumentar a TLP geral de um &nbsp;sistema. Uma combinação de espaço disponível aumentou (devido a &nbsp;processos de fabricação refinados) e a demanda por TLP aumento e levou &nbsp;ao desenvolvimento de CPUs multi-core. </div><div><br></div> <div><span class="fs11lh1-5"><b>Incentivos Comerciais</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vários &nbsp;negócios impulsionaram o desenvolvimento da arquitetura multicore. &nbsp;Durante décadas, foi possível melhorar o desempenho de uma CPU, &nbsp;reduzindo a área do circuito integrado, que diminuiu o custo por &nbsp;dispositivo. Como alternativa, mais transistores poderiam ser utilizados &nbsp;no projeto, o que aumentou a funcionalidade, especialmente para as &nbsp;arquiteturas CISC. Eventualmente, estas técnicas atingiram o seu limite e &nbsp;não puderam continuar a melhorar o desempenho da CPU. Múltiplos &nbsp;processadores tiveram que ser empregados para ganhar velocidade no &nbsp;processamento. Vários núcleos foram usados ​​no mesmo chip para melhorar &nbsp;o desempenho, o que poderia então levar a melhores vendas de CPUs que &nbsp;tinham dois ou mais núcleos. </div><div><br></div> <div><span class="fs11lh1-5"><b>Vantagens</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma &nbsp;das principais vantagens dos processadores multicore é também um dos &nbsp;principais motivos da sua invenção. Essa vantagem é a sua maior &nbsp;capacidade - comparado aos singlecores - de resfriamento; o que ainda &nbsp;possibilitou e ainda possibilita o aumento do poder de processamento. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Economia no preço de licenciamento de softwares proprietários, &nbsp;passando a ter um maior poder de processamento sem necessitar de uma &nbsp;nova máquina. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Processadores multicore também permitem maior desempenho com &nbsp;menor energia. Isso pode ser um fator importante em dispositivos móveis &nbsp;que funcionam com baterias. Uma vez que cada núcleo em multicore é &nbsp;geralmente mais eficiente em termos energéticos, o chip se torna mais &nbsp;eficiente do que ter um grande núcleo único e monolítico. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As outras vantagens quase que por completo relacionam-se com a &nbsp;capacidade de processamento, principalmente quando se trata da execução &nbsp;de mais de um aplicativo ao mesmo tempo ou mesmo e aplicativos capazes &nbsp;de realizar o seu processamento paralelamente, conseguindo assim &nbsp;trabalhar com dois ou mais núcleos concomitantemente. Nos processadores mais recentemente desenvolvidos existe também uma &nbsp;melhora no acesso a memória e na troca de dados entre os próprios &nbsp;núcleos. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Porém, é importante destacar também que para que a qualidade de &nbsp;processamento paralelo dos multicores seja utilizada na sua totalidade &nbsp;os softwares instalados na máquina devem ser escritos para aproveitar &nbsp;esse recurso; para isso as aplicações devem ser escritas utilizando e &nbsp;armazenando os conceitos de threads, assim uma única aplicação utilizará o poder de processamentos dos dois ou mais processadores. </div><div><br></div> <div><span class="fs11lh1-5"><b>Desvantagens</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Processadores &nbsp;multicore possuem um bom desempenho, performance, disponibilidade e &nbsp;segurança a um menor custo. Por outro lado, esta tecnologia possui &nbsp;algumas desvantagens, entre as principais podemos destacar: </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O aumento da utilização dos recursos computacionais fornecidos &nbsp;por processadores multicore requerem ajustes, tanto para o sistema &nbsp;operacional de apoio quanto para o software aplicativo já existente. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A capacidade dos processadores multi-core depende da utilização &nbsp;de vários segmentos dentro das aplicações para aumentar o desempenho da &nbsp;aplicação. &nbsp;</div><div><br></div> <div><span class="fs11lh1-5"><b>Arquitetura</b></span></div><div><br></div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Com &nbsp;o surgimento dos multicores tornou-se necessário algumas adaptações a &nbsp;nível de arquitetura para o melhor aproveitamento dos seus núcleos, e as &nbsp;primeiras a serem feitas tem como objetivo melhorar o paralelismo a &nbsp;nível de threads e assim criar uma arquitetura que propicie o chamado &nbsp;paralelismo ao nível do chip. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Algumas vantagens da arquitetura são: a melhor localização dos &nbsp;dados em se comparando com outras arquiteturas de multiprocessamento; a &nbsp;melhor comunicação entre as unidades e o número reduzido de quantidade &nbsp;de espaço e energia necessários. </div><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A arquitetura é geralmente um SMP, ou seja, um multiprocessamento simétrico; implementado em um circuito VLSI &nbsp;- Very Large Scale Integration. Essa é uma arquitetura onde dois ou &nbsp;mais processadores idênticos são ligados a uma única memória principal. &nbsp;Porém ao SMP existem outras alternativas de se criar uma arquitetura com &nbsp;variantes para o tratamento da memória ou até mesmo a comunicação entre &nbsp;os diversos núcleos presentes no processador.</div></div></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_4" class="imPageRow">
						
						</div>
						<div id="imCell_4" class=""  data-responsive-sequence-number="4"> <div id="imCellStyleGraphics_4"></div><div id="imCellStyleBorders_4"></div><div id="imTextObject_297_04">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_04_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div class="imTACenter"><span class="fs28lh1-5 ff1"><b>Clock do Processador</b></span></div><div class="imTALeft"><br></div><div class="imTALeft"><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em eletrônica e especialmente em circuitos digitais síncronos, o <b>sinal de relógio</b> (em inglês, <i><b>clock signal</b></i>) é um sinal usado para coordenar as ações de dois ou mais circuitos eletrônicos. Um sinal de clock oscila entre os estados alto e baixo, normalmente usando um ciclo de trabalho (<i>duty cicle</i>) de 50%, e gerando uma onda quadrada.
						 Circuitos que usam o sinal de clock para sincronização podem se 
						tornar ativos no ápice, na queda ou em ambos os momentos do sinal de clock (por exemplo, uma DDR SDRAM). <br></span></div><div class="imTALeft"><span class="fs11lh1-5 ff1"><br></span></div><div class="imTALeft"><div><b class="fs11lh1-5 ff1">Circuito Digital</b></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A maioria dos circuitos integrados
						 complexos o suficiente usa um sinais de clock para sincronizar as 
						diferentes partes do circuito. Em alguns casos, mais do que um ciclo de clock é necessário para executar uma ação previsível. Como os circuitos integrados
						 se tornaram mais complexos, o problema de fornecer sinais de clock precisos e sincronizados para todos os circuitos torna-se cada vez mais 
						difícil. O exemplo mais proeminente das tais circuitos complexos é o microprocessador, o componente central de computadores modernos, que se baseia em um sinal de clock, a partir de um oscilador de cristal. As únicas exceções são os circuitos assíncronos, tais como as CPU assíncronas.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Um sinal de clock também pode ser fechado, isto é, combinado 
						com um sinal de controle, que ativa ou desativa o sinal de clock em 
						uma determinada parte de um circuito. Esta técnica é frequentemente 
						usada para economizar energia desligando efetivamente partes de um 
						circuito digital quando não estão em uso.</span><br></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Sinal de Clock monofásico</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A maioria dos circuitos síncronos
						 modernos usam apenas um sinal de clock monofásico. Em outras 
						palavras, eles transmitem todos os sinal de clock em (efetivamente) 1 
						fio.
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Sinal de Clock bifásico</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em circuitos síncronos,
						 um sinal de clock bifásico refere-se a sinal de clock distribuídos 
						em 2 fios, cada um com pulsos não sobrepostos. Tradicionalmente, um fio é
						 chamado "fase 1", o outro fio transporta o sinal da "fase 2".
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Sinal de Clock tetrafásico</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O &nbsp;sinal de clock tetrafásico tem sinais distribuídos em 4 fios.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em alguns microprocessadores primitivos, tais como a família IMP-16 da National Semiconductor, um sinal de clock multifásico foi utilizado. No caso do IMP-16,
						 o sinal de clock tinha quatro fases, cada uma com 90 graus 
						separando-se da outra, a fim de sincronizar as operações do núcleo do 
						processador e dos seus periféricos. &nbsp;
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No entanto, a maioria dos microprocessadores e microcontroladores modernos usam um sinal de clock monofásico.
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Multiplicador de sinais de relógio</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Muitos microcomputadores modernos utilizam um "multiplicador de sinais de clock", que multiplica o sinal de clock externo (com um frequência inferior) à frequência de clock adequada do microprocessador. Isso permite que a CPU opere em uma 
						frequência muito maior do que o resto do computador, o que proporciona 
						ganhos de desempenho em situações que a CPU não precisa esperar por um 
						fator externo (como memória ou entrada / saída).
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Mudança de frequência dinâmica</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A
						 grande maioria dos dispositivos digitais não exige um sinal de clock de frequência constante (fixa). Enquanto os tempos mínimos e máximos de 
						sinal de clock são respeitados, o tempo entre os picos pode variar 
						muito de uma ponta a outra e vice-versa. Tais dispositivos digitais 
						funcionam tão bem com um gerador de sinais de clock que modifica sua 
						frequência (como espalhamento espectral, PowerNow!, Cool'n'Quiet, Passorrápido, etc.). Dispositivos que usam a lógica estática
						 nem mesmo têm um tempo máximo de sinal de clock; tais dispositivos 
						podem ser retardados e parados por tempo indeterminado, e em seguida 
						retomar a velocidade de sinal de clock completa em qualquer momento 
						posterior.
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Outros Circuitos</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Alguns circuitos integrados híbridos sensíveis, como conversores analógico-digitais de precisão, usam senoides em vez de ondas quadradas como sinal de clock, uma vez que as ondas quadradas possuem harmônicas de alta frequência que podem interferir com circuitos analógicos e causar ruído.
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Distribuição</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A maneira mais efetiva de transportar um sinal de clock para todas as partes necessárias de um circuito integrado com a menor inclinação (em inglês <i>clock skew</i>)
						 é uma grade metálica. Num processador de grandes dimensões, a energia 
						usada para transportar o sinal de clock pode ser superior a 30% do 
						total de energia gasto pelo circuito integrado. A estrutura toda com as 
						portas nos finais e todos os amplificadores no meio precisam ser 
						carregados e descarregados a cada ciclo. Para poupar energia, o <i>clock gating</i> desliga temporariamente parte da estrutura.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Os sinais de clock são tipicamente carregados com o maior <i>fan-out</i>
						 e operam com as maiores velocidades de qualquer sinal dentro do sistema
						 de sincronia. Desde que os sinais de dados são fornecidos com uma 
						referência temporal pelos sinais de clock, as formas de onda do sinal de clock precisam de ser particularmente limpas e nítidas. </span></div></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_5" class="imPageRow">
						
						</div>
						<div id="imCell_5" class=""  data-responsive-sequence-number="5"> <div id="imCellStyleGraphics_5"></div><div id="imCellStyleBorders_5"></div><div id="imTextObject_297_05">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_05_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div class="imTACenter"><span class="fs28lh1-5 ff1"><b>Cache do Processador</b></span></div><div class="imTALeft"><br></div><div class="imTALeft"><div><span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache do processador</b> (em inglês: <i>CPU cache</i>) é uma memória de acesso rápido. É usada pela Unidade Central de Processamento (<i>CPU</i>, &nbsp;o processador) com o objetivo de reduzir o tempo médio de acesso aos &nbsp;dados armazenados na memória. A cache é uma memória de pouco espaço, &nbsp;porém muito mais rápida e armazena as informações que são usadas com &nbsp;mais frequência pela CPU. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando a <i>CPU</i> precisa buscar uma informação na memória, ela &nbsp;busca primeiro pela cache. Se não encontrado, busca-se na Memória &nbsp;Principal, então devolve a informação para a <i>CPU</i> e armazena esta informação na cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Com os avanços tecnológicos, vários tipos de cache foram &nbsp;desenvolvidos. Atualmente há cache em processadores, discos rígidos, &nbsp;sistemas, servidores, nas placas-mãe, <i>clusters</i> &nbsp;de bancos de dados, entre outros. Qualquer dispositivo que requeira do &nbsp;usuário uma solicitação/requisição a algum outro recurso, seja de rede &nbsp;ou local, interno ou externo a essa rede, pode requerer ou possuir de &nbsp;fábrica o recurso de cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Por ser mais caro, o recurso mais rápido não pode ser usado para &nbsp;armazenar todas as informações. Sendo assim, usa-se o cache para &nbsp;armazenar apenas as informações mais frequentemente usadas. Nas unidades &nbsp;de disco também conhecidas como disco rígido (em inglês: <i>hard drive</i>, <i>HD</i>), também existem <i>chips</i> de cache nas placas eletrônicas que os acompanham.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><div><span class="fs11lh1-5 ff1"><b>Funcionamento</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache &nbsp;(do inglês, escondido) é uma memória interna ao processador usada para &nbsp;armazenamento temporário de dados que são usados com mais frequência &nbsp;pelo processador. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Outra definição mais precisa poderia ser: uma área de &nbsp;armazenamento temporária dentro do processador onde os dados &nbsp;frequentemente usados são acessados de forma mais rápida, sem &nbsp;necessidade de acesso à memória principal. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando a CPU necessita de um determinado endereço que está &nbsp;armazenado na memória, o primeiro lugar a buscar este endereço é na &nbsp;memória cache. Se o conteúdo está na cache, ocorre o acerto na cache, &nbsp;chamado de <i>cache hit</i> (quando o conteúdo requisitado pelo CPU é &nbsp;encontrado na cache), fazendo a informação ser acessada pela CPU sem &nbsp;necessidade de acesso à memória principal. Se o conteúdo não está na &nbsp;cache, ocorre uma falta de cache, chamado de <i>cache miss</i> (quando o &nbsp;conteúdo requisitado pela CPU não esta presente na cache), o que leva a &nbsp;CPU a buscar essa informação na memória principal. Como provavelmente &nbsp;essa informação será requisitada novamente (localidade temporal) o dado &nbsp;que foi buscado na RAM é copiado na cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Como a cache possui capacidade de armazenamento extremamente &nbsp;limitada (algo comum de acontecer devido ao seu custo), os novos dados &nbsp;que chegam da memória principal precisam ocupar o lugar de dados já &nbsp;presentes na cache provocando assim a evasão de dados menos recentes. A &nbsp;forma (heurística) utilizada para selecionar o elemento a ser retirado é &nbsp;conhecida como política de troca (<i>replacement policy</i>). Uma política de troca muito popular é a LRU (<i>least recently used</i>), que significa algo como “elemento menos usado recentemente”. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando um dado é escrito no cache, ele deve ser gravado no local &nbsp;de armazenamento em algum momento. O momento da escrita é controlado &nbsp;pela política de escrita (write policy). Existem diferentes políticas. A &nbsp;política de write-through (algo como “escrita através”) funciona da &nbsp;seguinte forma: a cada vez que um elemento é colocado no cache, ele &nbsp;também é gravado no local de armazenamento original. Alternativamente, &nbsp;pode ser utilizada a política de write-back (escrever de volta), onde as &nbsp;escritas não são directamente espelhadas no armazenamento. Ao invés, o &nbsp;mecanismo de cache identifica quais de seus elementos foram sobrepostos &nbsp;(marcados como sujos) e somente essas posições são colocadas de volta &nbsp;nos locais de armazenamento quando o elemento for retirado do cache. Por &nbsp;essa razão, quando ocorre um cache miss (falta de acesso ao cache pelo &nbsp;fato de um elemento não existir nele) em um cache com a política &nbsp;write-back, são necessários dois acessos à memória: um para recuperar o &nbsp;dado necessário e outro para gravar o dado que foi modificado no cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O mecanismo de write-back pode ser accionado por outras políticas &nbsp;também. O cliente pode primeiro realizar diversas mudanças nos dados do &nbsp;cache e depois solicitar ao cache para gravar os dados no dispositivo &nbsp;de uma única vez. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Os dados disponíveis nos locais de armazenamento original podem &nbsp;ser modificados por outras entidades diferentes, além do próprio cache. &nbsp;Nesse caso, a cópia existente no cache pode se tornar inválida. Da mesma &nbsp;forma, quando um cliente atualiza os dados no cache, as cópias do dado &nbsp;que estejam presentes em outros caches se tornarão inválidas. Protocolos &nbsp;de comunicação entre gerentes de cache são responsáveis por manter os &nbsp;dados consistentes e são conhecidos por protocolos de coerência. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Princípio da localidade de referência</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Podemos &nbsp;definir resumidamente localidade de referência como o método em que os &nbsp;dados são escritos/levados ate a memória cache consequentemente até a &nbsp;CPU. Existem dois tipos de localidade de Referência:</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Localidade Temporal</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O &nbsp;processador, ao longo de sua execução poderá requisitar uma informação &nbsp;que não esteja na cache. Isso faz com que esta informação seja buscada &nbsp;na memória Principal. Como a há uma grande probabilidade de essa &nbsp;informação ser executada novamente em um tempo próximo, ela é guardada &nbsp;(uma cópia) na memória cache. Desta maneira essa informação não &nbsp;precisará mais ser buscada na MP por um tempo.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Localidade Espacial</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando &nbsp;uma informação é buscada na MP, a localidade temporal faz com que esta &nbsp;informação seja copiada para a cache, porém, também haverá uma grande &nbsp;possibilidade de suas informações vizinhas serem requisitadas em um &nbsp;futuro próximo. Deste modo, junto com a informação requisitada, os &nbsp;vizinhos também serão copiados para a cache. As duas localidades temporal e espacial ocorrem juntas quando a informação é requisitada da MP. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Organizações de Memória Cache</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memórias cache são fisicamente organizadas através de linhas ou blocos de dados que podem ser organizados em conjuntos (<i>sets</i>). Essas formas de organização são descritas abaixo </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Mapeamento Direto</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No mapeamento direto, cada bloco da memória principal é mapeado para uma linha do cache, cada linha da cache possui 3 campos, <i>índice (ou linha), tag e o endereço da palavra.</i> O <i>tag</i> é usado para validar se a linha procurada é a mesma que esta na cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O <i>índice</i> serve como um endereço da cache, apontado onde pode estar a linha procurada. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O <i>endereço da palavra</i> são os bits menos significativos que identificam uma palavra dentro de um bloco da memória Principal. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No início do mapeamento, cada bloco da memória principal tem sua &nbsp;linha exclusiva mapeada na cache. Este mapeamento é facilmente &nbsp;implementado. Tudo começa com o endereço da memória Principal. Através &nbsp;deste endereço, para o acesso a cache, deve se identificar os três &nbsp;campos citados acima. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Para achar o End. da palavra, é necessário fazer uma simples &nbsp;conta de logaritmo, tendo em base a quantidade de bytes por linha da &nbsp;cache. <b>LOG<sub><small>2</small></sub> Nr bytes</b>. Para achar o índice, deve levar em conta o número de linhas que possui a cache, fazendo o mesmo cálculo de logaritmo: <b>LOG<sub><small>2</small></sub> Nr Linhas</b> O restante será designado a tag.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Suponhamos, em um exemplo que o endereço da linha seja de 32 bits, e a cache possui 1024 linhas com 64 Bytes cada linha. <i>Log<small>2</small> 64 = 6 bits para End.</i> </span></div><div><span class="fs11lh1-5 ff1">Log<small>2</small> 1024 = 10 bits para índice. 32- (10+6)=16 bits para tag. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Na operação de leitura, a CPU envia um endereço de 32 bits para o &nbsp;circuito de controle da cache que já identifica os campos para começar a &nbsp;pesquisa nas linhas. Inicialmente começando pelo índice, onde a busca &nbsp;ocorre para tentar achar a linha desejada. Após, o próximo passo é &nbsp;comparar os valores da tag do endereço com o valor da tag da linha. Se &nbsp;forem iguais, em seguida, a palavra que esta na linha (6 últimos bits) é &nbsp;transferida pra CPU. Caso os valores das tags não forem iguais, isso significa que a linha &nbsp;desejada pela CPU não esta na cache, portanto é buscada na MP e &nbsp;transferida para a mesma linha, substituindo-a. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Totalmente Associativa</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No &nbsp;mapeamento direto, cada linha da memória principal tinha um lugar &nbsp;exclusivo na memória cache. Já no mapeamento associativo não, aqui, cada &nbsp;linha da MP pode ser carregada em qualquer lugar da cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Neste modo haverá apenas dois campos. A tag e o end. da palavra. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Estes dois campos têm as mesmas funções dos dois campos do &nbsp;mapeamento direto. Porem o campo tag terá uma quantidade de bits maior. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No mapeamento associativo, para verificar se a linha esta na &nbsp;cache, é comparado a tag de cada linha na cache com a tag do endereço &nbsp;apresentado pela CPU. Se achou, então os bytes da palavra são &nbsp;transferidos para a CPU, caso contrario, busca-se o endereço na MP e &nbsp;guarda na cache.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Associatividade por Conjunto (N-Way)</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Este &nbsp;tipo de organização intercala as vantagens dos outros dois mapeamentos &nbsp;citados acima, acabando com a comparação exaustiva dos campos tag &nbsp;(causado no mapeamento totalmente associativo)e o problema de conflito &nbsp;de endereços por uma mesma linha na cache (causado no mapeamento &nbsp;direto). Neste caso, a cache nada mais é do que uma série de conjuntos, &nbsp;constituídos por uma série de linhas em cada conjunto. A sigla N-Way &nbsp;significa o tamanho dos conjuntos da cache, onde N é a quantidade de &nbsp;palavras em um conjunto. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cada linha da memória principal pode ser armazenada em qualquer &nbsp;linha de um conjunto específico. O conjunto é determinado pelo endereço, &nbsp;que é dividido em 3 campos: <i>TAG, Nr do conjunto e o End da palavra</i>. &nbsp;Dado um endereço a cache para leitura, ela separa os endereços nesses &nbsp;três campos. O primeiro campo a ser analisado é o Nr do conjunto, que &nbsp;define em qual conjunto a linha vai ser pesquisada. Apos, o campo TAG é &nbsp;comparado com todas as linhas deste conjunto para achar a linha &nbsp;desejada. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Algoritmos de substituição de dados</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ai &nbsp;podemos se perguntar. Mas e quando a cache encher? É aqui que entra o &nbsp;papel dos algoritmos de substituição. Eles tem a função de definir quais &nbsp;linhas com informações atualmente armazenadas vão ser retiradas para &nbsp;dar lugar a uma novas linhas com informações. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Alguns algoritmos são citados abaixo: </span></div><div><span class="fs11lh1-5 ff1"><b><i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Least Recently Used (LRU)</i>:</b> Este algoritmo escolhe a linha que esta a mais tempo sem uso pela CPU e substitui pela nova linha. </span></div><div><span class="fs11lh1-5 ff1"><b><i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First Input, First Output (FIFO)</i>:</b> FIFO se resume a &nbsp;uma fila qualquer. Um exemplo prático seria uma fila de banco, o &nbsp;primeiro a entrar será o primeiro a ser atendido. No caso da cache, a &nbsp;linha que a mais tempos esta armazenada na cache sera substituída, &nbsp;independentemente se a CPU estiver usando ou não. </span></div><div><span class="fs11lh1-5 ff1"><b><i> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Least Frequently Used (LFU)</i>:</b> O algoritmo escolhe a &nbsp;linha de acordo com a sua referência, ou seja, a linha que tiver menos &nbsp;acessos por parte da CPU vai ser a escolhida para substituição. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Modelos de cache</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1">Estes modelos consideram uma hierarquia de memória que possua cache de dados L1 com mapeamento direto.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Cache de Vítimas</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A <i>cache vítima</i> &nbsp;ou CV é uma pequena cache, localizada entre a L1 e os níveis inferiores &nbsp;da cache, usado para armazenar blocos/linhas que foram "expulsos" da &nbsp;cache principal durante a substituição. O cache de vítima geralmente é &nbsp;totalmente associativo e destina-se a reduzir o número de erros de &nbsp;conflito. Na verdade, apenas uma pequena fração dos acessos memória do &nbsp;programa exigem alta associatividade. O cache de vítima explora essa &nbsp;propriedade fornecendo alta associatividade para apenas esses acessos. A &nbsp;política de troca de blocos na CV é LRU. Foi introduzida por Norman Jouppi na década de 90.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Stream Buffer</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stream &nbsp;Buffer (SB) é uma simples estrutura dentro da cache, que faz buscas &nbsp;para a cache antecipadamente. Esta estrutura reduz o numero de faltas &nbsp;compulsórias. Esta falta ocorre quando um bloco foi pela primeira vez &nbsp;referenciado pela CPU. Isso porque quando ocorre esta falta, o SB pega o &nbsp;endereço desta referência e busca os blocos subsequentes e armazena em &nbsp;uma fila, enquanto a fila não encher, a busca continua. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em uma requisição da CPU, a referência requisitada é buscada &nbsp;tanto na cache como na SB. Caso ocorra um acerto na fila da SB, o &nbsp;bloco/linha é entregue pra CPU e armazenado na cache. Se ocorrer uma &nbsp;falta na fila e na cache também, os blocos que estão na fila são &nbsp;"expulsos" e o processo de busca retorna a partir do endereço da &nbsp;referência que ocorreu a falta.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Cache em níveis</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Com &nbsp;a evolução na velocidade dos dispositivos, em particular nos &nbsp;processadores, o cache foi dividido em níveis, já que a demanda de &nbsp;velocidade a memória é tão grande que são necessários caches grandes com &nbsp;velocidades altíssimas de transferência e baixas latências. Sendo muito &nbsp;difícil e caro construir memórias caches com essas características, &nbsp;elas são construídas em níveis que se diferem na relação tamanho X &nbsp;desempenho. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <dl><dt><span class="fs11lh1-5 ff1"><b> &nbsp;Cache L1 </b></span></dt><dt><span class="fs11lh1-5 ff1"><br></span></dt></dl> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma pequena porção de memória estática. Ela pode estar dentro do chip &nbsp;da CPU ou fora dele, existe um ganho de velocidade mais desejável com a &nbsp;cache dentro do chip, pois a comunicação ocorre melhor dentro do chip &nbsp;do que entre chips, o que vem fazendo, atualmente, os chips conterem &nbsp;essa pequena parte da cache (L1) dentro do chip. Mas não termina por aí, &nbsp;para intercalar essas duas partes (dentro e fora), ela foi dividida em 2 &nbsp;níveis: a parte dentro do chip (L1) e a parte de fora do chip (L2).</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em alguns tipos de processador, como o Pentium 2, o L1 é dividido &nbsp;em dois níveis: dados e instruções (que "dizem" o que fazer com os &nbsp;dados). O primeiro processador da Intel a ter o cache L1 foi o i486 com &nbsp;8KB. Geralmente tem entre 16KB e 128KB; hoje já encontramos &nbsp;processadores com até 16MB de cache. &nbsp;</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <dl><dt><span class="fs11lh1-5 ff1"><b> &nbsp;Cache L2 </b></span></dt><dt><span class="fs11lh1-5 ff1"><br></span></dt></dl> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Possuindo o Cache L1 um tamanho reduzido e não apresentando uma &nbsp;solução ideal, foi desenvolvido o cache L2, que contém muito mais &nbsp;memória que o cache L1. Ela é mais um caminho para que a informação &nbsp;requisitada não tenha que ser procurada na lenta memória principal. &nbsp;Alguns processadores colocam esse cache fora do processador, por &nbsp;questões econômicas, pois um cache grande implica num custo grande, mas &nbsp;há exceções, como no Pentium II, por exemplo, cujas caches L1 e L2 estão &nbsp;no mesmo cartucho que está o processador. A memória cache L2 é, &nbsp;sobretudo, um dos elementos essenciais para um bom rendimento do &nbsp;processador mesmo que tenha um clock baixo. Um exemplo prático é o caso &nbsp;do Intel Itanium 9152M (para servidores) que tem apenas 1.6 GHz de clock &nbsp;interno e ganha de longe do atual Intel Extreme, pelo fato de possuir &nbsp;uma memória cache de 24MB. Quanto mais alto é o clock do processador, &nbsp;mais este aquece e mais instável se torna. Os processadores Intel &nbsp;Celeron tem um fraco desempenho por possuir menos memória cache L2. Um &nbsp;Pentium M 730 de 1.6 GHz de clock interno, 533 MHz FSB e 2 MB de cache &nbsp;L2, tem rendimento semelhante a um Intel Pentium 4 2.4 GHz, aquece muito &nbsp;menos e torna-se muito mais estável e bem mais rentável do que o Intel &nbsp;Celeron M 440 de 1.86 GHz de clock interno, 533 MHz FSB e 1 MB de cache &nbsp;L2. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <dl><dt><span class="fs11lh1-5 ff1"><b> &nbsp;Cache L3 </b></span></dt><dt><span class="fs11lh1-5 ff1"><br></span></dt></dl> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Terceiro nível de cache de memória. Inicialmente utilizado pelo AMD &nbsp;K6-III (por apresentar o cache L2 integrado ao seu núcleo) utilizava o &nbsp;cache externo presente na placa-mãe como uma memória de cache adicional. &nbsp;Ainda é um tipo de cache raro devido à complexidade dos processadores &nbsp;atuais, com suas áreas chegando a milhões de transístores por &nbsp;micrómetros ou nanómetros de área. Ela será muito útil, é possível a &nbsp;necessidade futura de níveis ainda mais elevados de cache, como L4 e &nbsp;assim por diante. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><b class="fs11lh1-5 ff1">Smart Cache</b></div><div> &nbsp;</div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Smart Cache</b> é um método de cache de nível 2 ou nível 3 para núcleos de execução múltipla, desenvolvido pela Intel. O <i>Smart Cache</i> compartilha a memória cache real entre os núcleos de um processador multi-core. &nbsp;Em comparação com um cache per-core dedicado, a taxa geral de falta de &nbsp;cache diminui quando nem todos os núcleos precisam de partes iguais do &nbsp;espaço do cache. Conseqüentemente, um único núcleo pode usar o cache de &nbsp;nível 2 ou nível 3, se os outros núcleos estiverem inativos. Além disso, o cache compartilhado torna mais rápido a partilha de memória entre diferentes núcleos de execução.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Caches unificadas/Caches separadas</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando &nbsp;o nível L1 da cache começou a aparecer dentro do chip da CPU, apenas &nbsp;uma cache inteira era usada para armazenar dados e instruções, porem &nbsp;tornou-se comum separar a cache em duas partes, 1 dedicada a armazenar &nbsp;dados e a outra dedicada a instruções. Assim, quando o processador busca &nbsp;um dado, ele busca na cache de dados, e quando busca uma instrução, ele &nbsp;busca na cache de instrução. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ate um certo tamanho, a vantagem fica com a cache unificada, pois &nbsp;a cache tende a equilibrar as buscas por instruções dados, ou seja, se o &nbsp;processador tende a buscar mais instruções, a cache vai armazenar mais &nbsp;instruções. A mesma coisa acontece se o processador busca mais dados. &nbsp;Além disso, somente uma cache precisa ser projetada e implementada. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mas o futuro tende a continuar com a cache separada, &nbsp;principalmente em computadores superescalares por ex. o PowerPC. Pois &nbsp;esses processadores escalares, executam instruções paralelas e fazem a &nbsp;pré-busca de instruções futuras previstas. Na cache separada o &nbsp;processador busca antecipadamente as instruções e guarda em um buffer &nbsp;com instruções a serem armazenadas. A cache separada ainda não precisa &nbsp;de políticas de escrita, e tem barramentos independentes, onde cada &nbsp;cache se liga ao CPU.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Caches inclusivos e exclusivos</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Caches &nbsp;Multi-level introduzem novos aspectos na sua implementação. Por &nbsp;exemplo, em alguns processadores, todos os dados no cache L1 devem &nbsp;também estar em algum lugar no cache L2. Estes caches são estritamente &nbsp;chamados de inclusivos. Outros processadores (como o AMD Athlon) têm &nbsp;caches exclusivos — os dados podem estar no cache L1 ou L2, nunca em &nbsp;ambos. Ainda outros processadores (como o Pentium II, III, e 4 de &nbsp;Intel), não requerem que os dados no cache L1 residam também no cache &nbsp;L2, embora possam frequentemente fazê-lo. Não há nenhum nome universal &nbsp;aceitado para esta política intermediária, embora o termo inclusivo seja &nbsp;usado. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A vantagem de caches exclusivos é que são capazes de armazenarem &nbsp;mais dados. Esta vantagem é maior quando o cache L1 exclusivo é de &nbsp;tamanho próximo ao cache L2, e diminui se o cache L2 for muitas vezes &nbsp;maior do que o cache L1. Quando o L1 falha e o L2 acerta acesso, a linha &nbsp;correta do cache L2 é trocada com uma linha no L1. Esta troca é um &nbsp;problema, uma vez que a quantidade de tempo para tal troca ser realizada &nbsp;é relativamente alta. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma das vantagens de caches estritamente inclusivos é que quando &nbsp;os dispositivos externos ou outros processadores em um sistema &nbsp;multiprocessado desejam remover uma linha do cache do processador, &nbsp;necessitam somente mandar o processador verificar o cache L2. Nas &nbsp;hierarquias de cache exclusiva, o cache L1 deve ser verificado também. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma outra vantagem de caches inclusivos é que um cache maior pode &nbsp;usar linhas maiores do cache, que reduz o tamanho das Tags do cache L2. &nbsp;(Os caches exclusivos requerem ambos os caches teres linhas do mesmo &nbsp;tamanho, de modo que as linhas do cache possam ser trocadas em uma falha &nbsp;no L1 e um acerto no L2). </span></div><div><span class="fs11lh1-5 ff1">Técnicas de escrita de dados do cache </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Política de escrita</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Quando &nbsp;a CPU necessita fazer uma operação de escrita na memória, esta ocorre &nbsp;diretamente na cache. Mas como a cache não é uma memória principal, em &nbsp;algum momento a MP precisa ser atualizada, para manter a integridade. &nbsp;Isso deve acontecer, pois quando uma linha vai ser substituída na cache, &nbsp;antes de isso acontecer, é preciso verificar se essa linha não foi &nbsp;alterada na cache e também não foi alterada na MP. Caso ela tenha sido &nbsp;alterada em algum dos dois casos, isto significa que a linha da cache &nbsp;esta diferente da linha da MP. Isto não pode acontecer, pois a MP &nbsp;precisa estar tão mantida corretamente quanto a cache.</span></div><div><span class="fs11lh1-5 ff1">Hoje são encontradas algumas políticas de escritas que resolvem este problema, cada uma com suas vantagens e desvantagens. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;Write-Back Cache</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Usando &nbsp;esta técnica a CPU escreve dados diretamente no cache, cabendo ao &nbsp;sistema a escrita posterior da informação na memória principal. Como &nbsp;resultado, o CPU fica livre mais rapidamente para executar outras &nbsp;operações. Em contrapartida, a latência do controlador pode induzir &nbsp;problemas de consistência de dados na memória principal, em sistemas &nbsp;multiprocessados com memória compartilhada. Esses problemas são tratados &nbsp;por protocolos de consistência do cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Exemplo: </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A escrita de um endereço é feita inicialmente numa linha do &nbsp;cache, e somente no cache. Quando mais tarde algum novo endereço &nbsp;precisar desta linha do cache, estando esta já ocupada, então o endereço &nbsp;inicial é guardado na memória e o novo endereço ocupa-lhe o lugar na &nbsp;respectiva linha do cache. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Para reduzir a frequência de escrita de blocos de endereços na memória aquando da substituição é usado um <i>"dirty bit"</i>, &nbsp;este é um bit de estado (atualização), ou seja, quando o endereço é &nbsp;instanciado inicialmente numa linha do cache, estando essa linha vazia, o &nbsp;valor inicial é implicitamente '0', quando o bloco do endereço é &nbsp;modificado (quando ocorre uma substituição) o valor inicial passa a '1' e &nbsp;diz-se que o bloco do endereço está "dirty".</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><i><b>Vantagens</b></i> </span></div><div><span class="fs11lh1-5 ff1"><i><b><br></b></i></span></div> <ul><li><span class="fs11lh1-5 ff1">a escrita ocorre à velocidade do cache;</span></li> <li><span class="fs11lh1-5 ff1">escritas múltiplas de um endereço requerem apenas uma escrita na memória;</span></li> <li><span class="fs11lh1-5 ff1">consome menos largura de banda.</span></li></ul> <div><span class="fs11lh1-5 ff1"><i><b><br></b></i></span></div><div><span class="fs11lh1-5 ff1"><i><b>Desvantagens</b></i> </span></div><div><span class="fs11lh1-5 ff1"><i><b><br></b></i></span></div> <ul><li><span class="fs11lh1-5 ff1">difícil de implementar;</span></li> <li><span class="fs11lh1-5 ff1">nem sempre existe consistência entre os dados existentes no cache e na memória;</span></li> <li><span class="fs11lh1-5 ff1">leituras de blocos de endereços no cache podem resultar em escritas de blocos de endereços "dirty" na memória.</span></li></ul> <div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Write-Through Cache</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;É &nbsp;a técnica mais simples usada. As operações de escrita são feitas tanto &nbsp;na memória Principal como na cache, garantindo que a memória principal &nbsp;esteja sempre valida. Este tipo de política providencia pior desempenho &nbsp;do que Write-Back Cache, pois ela gera um grande trafego na memória &nbsp;principal, podendo formar gargalos, mas é mais simples de implementar e &nbsp;tem a vantagem da consistência interna, porque o cache nunca está &nbsp;dessincronizada com a memória como acontece com a técnica Write-Back &nbsp;Cache.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><i class="fs11lh1-5 ff1"><b>Vantagens</b></i><br></div><div><i class="fs11lh1-5 ff1"><b><br></b></i></div> <ul><li><span class="fs11lh1-5 ff1">fácil de implementar;</span></li> <li><span class="fs11lh1-5 ff1">um "cache-miss" nunca resulta em escritas na memória;</span></li> <li><span class="fs11lh1-5 ff1">a memória tem sempre a informação mais recente.</span></li></ul> <div><span class="fs11lh1-5 ff1"><i><b><br></b></i></span></div><div><span class="fs11lh1-5 ff1"><i><b>Desvantagens</b></i> </span></div><div><span class="fs11lh1-5 ff1"><i><b><br></b></i></span></div> <ul><li><span class="fs11lh1-5 ff1">a escrita é lenta;</span></li> <li><span class="fs11lh1-5 ff1">cada escrita necessita de um acesso à memória;</span></li> <li><span class="fs11lh1-5 ff1">consequentemente usa mais largura de banda da memória;</span></li> <li><span class="fs11lh1-5 ff1">alto uso do barramento da memória.</span></li></ul> <div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>Técnicas de "Write Miss"</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Write Allocate</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O &nbsp;bloco de endereço é carregado na ocorrência seguindo-se uma acção de &nbsp;"write hit". O "Write Allocate" é usado com frequência em caches de &nbsp;"Write Back". </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;No Write Allocate</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O &nbsp;bloco de endereço é diretamente modificado na memória, não é carregado &nbsp;no cache. O "No Write Allocate" é usado frequentemente em caches de &nbsp;"Write Through". </span><span class="fs11lh1-5 ff1"><br></span></div></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_6" class="imPageRow">
						
						</div>
						<div id="imCell_7" class=""  data-responsive-sequence-number="6"> <div id="imCellStyleGraphics_7"></div><div id="imCellStyleBorders_7"></div><div id="imTextObject_297_07">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_07_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div class="imTACenter"><span class="fs28lh1-5 ff1"><b>O que é Litografia?</b></span></div><div class="imTALeft"><br></div><div class="imTALeft"> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bem, voltando ao assunto inicial, a litografia serve para o controle &nbsp;de medida dos transistores, tudo bem, mas, porque a litografia sempre &nbsp;vai diminuindo?</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Para que a capacidade do chip seja maior, é preciso que o número de &nbsp;transistores seja cada vez maior em seu interior, e para isso, você &nbsp;precisa diminuir cada vez mais o tamanho do circuito como um todo. Pois &nbsp;como seria possível inserir milhares de transistores no núcleo de um &nbsp;processador sem aumentar seu tamanho físico?</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;É aí que entra a litografia, que é parte do processo de como esses &nbsp;circuitos são construídos. Não é possível manusear transistores de &nbsp;tamanho microscópico, e é por isso que eles são diretamente esculpidos &nbsp;sobre o silício, esse processo de construção de um processador é algo &nbsp;realmente complexo, pode levar muitos e muitos dias para ser concluído, &nbsp;isso, sem falar nos projetos dos circuitos que já tem que estar prontos &nbsp;muito antes de a construção do processador começar. Esse árduo trabalho &nbsp;de projetar os circuitos é feito pelos engenheiros que definem em quais &nbsp;áreas do chip as diferentes partes (cache, controlador de memória, &nbsp;vídeo, entre outros) que o compõem devem ficar e como elas vão ser &nbsp;interligadas. Tudo isso tem uma importância extrema, já que se existe &nbsp;apenas um erro, pode deixar milhares de processadores inutilizáveis. Ao &nbsp;final do projeto vem a parte da construção em si, a parte de esculpir os &nbsp;transistores no silício, mas o fato é, como fazer com que o projeto &nbsp;feito em tamanho grande possa ser impresso microscopicamente no wafer de &nbsp;silício? A litografia também está aqui. Antes do início da construção, o &nbsp;silício é coberto com um material fotorresistente e em seguida é &nbsp;aplicada luz ultravioleta para realizar a transferência do diagrama de &nbsp;circuitos para a superfície do disco. Nesse momento a luz passa por uma &nbsp;matriz do circuito construído em tamanho grande, e logo após, por uma &nbsp;lente que estará reduzindo essa matriz até que ela seja pequena o &nbsp;suficiente para ser escrita no disco, centenas de vezes, uma ao lado da &nbsp;outra.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Depois de todo esse processo, as partes que foram expostas a luz, se &nbsp;tornam solúveis. Após o processo um banho de produtos químicos remove &nbsp;essas partes, e também o líquido fotorresistente, e desse modo, o &nbsp;circuito pode ser visto na superfície do wafer de silício.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vale lembrar que o silício é semicondutor, então, é preciso revestir &nbsp;toda sua superfície com uma camada de proteção, que vai evitar os curtos &nbsp;circuitos quando o cobre for aplicado. Logo após, é feito o processo de &nbsp;galvanoplastia, no qual os íons de cobre são transferidos para o wafer &nbsp;de silício. O excesso de cobre é removido e os contatos dos transistores &nbsp;e demais componentes do chip são expostos. Nessa fase o processador já &nbsp;está quase pronto e parte para a fase de testes.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O disco, finalmente, é cortado e todos os núcleos recém criados são &nbsp;preparados para o encapsulamento final, onde são conectados aos &nbsp;terminais definitivos que os ajudará a proteger e, também, dissipar o &nbsp;calor gerado pela CPU.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Então, a litografia nada mais é que a redução de tamanho dos &nbsp;transistores e o circuito dentro dos processadores. Apenas para uma &nbsp;ideia, se o tamanho dos transistores continuassem os mesmos, um core i7 &nbsp;novo seria 450 vezes maior que o primeiro Pentium, algo impensável para &nbsp;um computador doméstico. Outra vantagem também é a redução do consumo de &nbsp;energia e da geração de calor, então, sempre quando ver o termo &nbsp;“litografia XX nm”, lembre-se que trata do processo de construção e &nbsp;tamanho dos transistores de um processador. Abaixo há alguns exemplos de &nbsp;litografia de alguns processadores:</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1">— <strong>Intel Pentium 60MHz (1993)</strong> — 3,1 milhões de transistores — 800nm<br> — <strong>Intel Core i7-4790k 4.0GHz (2014)</strong> — 1,4 bilhão de transistores — 22nm<br> — <strong>AMD Ryzen 7 1800X (2017)</strong> — 4,8 bilhões de transistores — 14nm</span></div><div><div><span class="fs11lh1-5 ff1">— <strong>AMD Ryzen 7 3800X (2019) </strong>—<strong> </strong>19 bilhões de transistores — 7nm</span></div></div><div><strong class="fs11lh1-5 ff1"><br></strong></div><div><strong class="fs11lh1-5 ff1"><br></strong></div><div><strong class="fs11lh1-5 ff1">Estamos Chegando no Fim da Lei de Moore?</strong></div><div><strong class="fs11lh1-5 ff1"><br></strong></div><div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Se 4 ou 5 anos já pode ser considerado um tempo enorme quando falamos &nbsp;de tecnologia, o fato de que a Lei de Moore tenha funcionado por mais &nbsp;de 50 anos chega a ser surpreendente. Não se trata de uma Lei, &nbsp;propriamente, mas sim uma espécie de guia (“profecia auto-realizável” &nbsp;seria um termo mais correto) seguido pelos principais fabricantes de &nbsp;semicondutores na hora de projetar seus chips, e tem funcionado muito &nbsp;bem até hoje. Já exploramos o que é a Lei de Moore em um artigo dedicado &nbsp;ao tema, já que ela praticamente moldou a forma como nossos &nbsp;computadores, tablets e até mesmo smartphones funcionam.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div> &nbsp;</div> <span class="fs11lh1-5 ff1"><b>O que é a Lei de Moore?</b><br></span><ul> </ul> <div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mas &nbsp;parece que essa Lei está chegando ao fim; e por vários motivos, o que &nbsp;acabará resultando em um foco maior em eficiência energética em vez de &nbsp;poder de processamento, além de uma mudança na relação entre software e &nbsp;hardware como conhecemos hoje. Vamos entender melhor isso nas próximas &nbsp;linhas.</span></div> <div><span class="fs11lh1-5 ff1">Limites físicos e econômicos</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Resumidamente, a &nbsp;Lei de Moore diz que a capacidade de transistores dos processadores &nbsp;dobra a cada 18 meses. Geralmente, mais transistores significa mais &nbsp;desempenho e, até um certo momento, menos calor dissipado. É uma forma &nbsp;bem reducionista de explicá-la, mas nos serve como um bom ponto de &nbsp;partida. Porém, essa miniaturização de transistores já demonstra sinais &nbsp;de estar chegando ao fim, já que o silício, principal componente, começa &nbsp;a perder suas propriedades físicas. Mais do que isso, reduzir &nbsp;progressivamente a litografia está se mostrando exponencialmente mais &nbsp;caro. E complicado. </span></div><section><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Participe do nosso Grupo de Cupons e Descontos no Whatsapp e garanta sempre o menor preço em suas compras de produtos de tecnologia. Na &nbsp;data de publicação deste artigo, a geração Skylake de processadores &nbsp;Intel é a família mais recente, representando o que há de melhor e mais &nbsp;moderno na indústria. São construídos em um processo de fabricação de 14 &nbsp;nanômetros, assim como a geração imediatamente anterior (Broadwell) e &nbsp;trazem embarcado as principais tecnologias da empresa, como o SpeedStep. &nbsp;Para chegar até aqui, a Intel &nbsp;enfrentou algumas dificuldades, como a necessidade de adotar &nbsp;“transistores 3D” e diversos atrasos para anunciar o Broadwell, &nbsp;mostrando que a redução de 22 nanômetros para 14 nanômetros foi mais &nbsp;difícil do que a empresa previu inicialmente.</span></section><section><span class="fs11lh1-5"><br></span></section><section><span class="fs11lh1-5"><br></span></section><section class="imTACenter"><span class="fs28lh1-5 ff1"><b>Oque é Instruções e Extenções?</b></span></section><section class="imTACenter"><span class="fs11lh1-5"><br></span></section><section><span class="fs11lh1-5"><br></span></section><section><span class="fs11lh1-5"><br></span></section><section><div><span class="fs11lh1-5 ff1"><b>Streaming SIMD Extensions</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SSE</b> (<i><b>S</b>treaming <b>S</b>IMD <b>E</b>xtensions</i>, inicialmente chamado <b>ISSE</b>, de <i><b>I</b>nternet <b>S</b>treaming <b>S</b>IMD <b>E</b>xtensions</i>) é um conjunto de instruções do tipo SIMD projetado pela Intel. O nome completo significa "Extensões SIMD para streaming". O SSE traz 70 novas instruções em relação ao conjunto de instruções anterior, do Pentium MMX. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O SSE foi primeiro conhecido como <b>KNI</b>, de <i>Katmai New Instructions</i>, onde &nbsp;<i>Katmai</i> &nbsp;era o apelido do primeiro Pentium III com núcleo revisto. Durante o &nbsp;projeto Katmai a Intel procurava distingui-lo da sua linha anterior de &nbsp;produtos, particularmente do projeto Pentium II. &nbsp;</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O SSE foi uma resposta à tecnologia 3DNow! da AMD, &nbsp;lançada um ano antes. Mas a AMD rapidamente contra-atacou, aproveitando &nbsp;do projeto da Intel e adicionou suporte às instruções SSE, começando &nbsp;assim a era do famoso processador Athlon XP. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A Intel ficou desapontada com o MMX, sua primeira iniciativa de desenvolvimento SIMD para IA-32. O MMX tinha dois grandes problemas: ele reusava registradores de ponto flutuante, o que fazia com que a CPU &nbsp;ficasse impossibilitada de trabalhar simultaneamente com instruções de &nbsp;ponto flutuante e SIMD. Por isso, o paralelismo só era conseguido com &nbsp;instruções de aritmética com inteiros. &nbsp;</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O <b>SSE</b> adiciona oito novos registradores 128-bits, conhecidos como <i>XMM0</i> até <i>XMM7</i>. Cada registro pode armazenar quatro &nbsp;&nbsp;números 32-bit de ponto flutuante ao mesmo tempo (single-precision). As extensões de 64 bits, tanto na Intel quanto da AMD, acrescentam mais 8 registros <i>XMM8</i> até <i>XMM15</i>. Além deles foi também adicionado um novo registrador, de controle e de status, chamado <i>MXCSR</i>. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Como esses novos registradores de 128 bits são estados de programa adicionais que o sistema operacional &nbsp;(SO) deve preservar entre mudanças de contexto de tarefas, eles devem &nbsp;permanecer desabilitados até que o sistema operacional os habilite &nbsp;explicitamente. Isto significa que o SO deve saber como usar as &nbsp;instruções FXSAVE e FXRSTR, que são o par de instruções estendidas que &nbsp;podem, respectivamente, salvar e restaurar todos os estados dos &nbsp;registradores x87 e SSE, de uma única vez. Este suporte foi rapidamente estendido para todos os principais sistemas operacionais para IA-32. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Como o SSE inclui suporte a ponto flutuante, ele tem mais usos do que o MMX, pois atualmemente as &nbsp;placas de vídeo &nbsp;podem tratar internamente todos os cálculos com inteiros. As operações &nbsp;SIMD inteiras ainda podem ser realizadas com 8 registradores de 64 bits &nbsp;do MMX. Como se sabe, os registradores MMX são obtidos renomeando-se (ou &nbsp;<i>aliasing</i>) os 8 registradores da FPU. Posteriormente, no SSE2, &nbsp;a Intel complementou o SSE com suporte a cálculos inteiros. Apesar de &nbsp;redundantes, as operações MMX podem ser executadas com as operações SSE, &nbsp;o que oferece maior desempenho em situações limitadas. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O primeiro CPU a ter suporte ao <b>SSE</b> foi o Pentium III, que compartilhava recursos entre o <b>SSE</b> e o FPU. &nbsp;As aplicações eram compiladas de forma a utilizar instruções <b>FPU</b> e <b>SSE</b> em paralelo, mas os processadores &nbsp;&nbsp;Pentium III não eram capazes de operar estes dois tipos de instruções &nbsp;simultaneamente (num mesmo ciclo). &nbsp;Estas limitações reduziram a &nbsp;eficiência do chamado <i>pipelining</i>, embora os registros isolados <i>XMM</i> permitiam instruções <i>SIMD</i> e operações escalares de ponto flutuante serem misturadas mas não tão eficientes quanto o modo <i>MMX/floating point</i>. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Versões posteriores</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><ul><li><span class="fs11lh1-5 ff1"><b>SSE2</b> foi introduzida com os processadores Pentium 4, e trouxeram melhorias significativas ao <b>SSE</b> (que alguns programadores passaram a chamar de "SSE1"). &nbsp;SSE2 adds new math instructions for <i>double-precision</i> &nbsp;(64-bit) floating point and 8/16/32-bit integer data types, all &nbsp;operating on the same 128-bit XMM vector register-file previously &nbsp;introduced with SSE. &nbsp;SSE2 enables the programmer to perform SIMD math &nbsp;of virtually any type (from 8-bit integer to 64-bit float) entirely with &nbsp;the XMM vector-register file, without the need to touch the (legacy) &nbsp;MMX/FPU registers. &nbsp;Many programmers consider SSE2 to be "everything SSE &nbsp;should have been", as SSE2 offers an orthogonal set of instructions for &nbsp;dealing with common datatypes.</span></li> <li><span class="fs11lh1-5 ff1"><b>SSE3</b> chamado de <i>Prescott New Instructions</i>, é um <i>upgrade</i> incremental ao <b>SSE2</b>, adicionando instruções matemáticas orientadas à DSP (<i>DSP-oriented</i>) e algumas instruções de manipulação de processos (<i>thread</i>).</span></li> <li><span class="fs11lh1-5 ff1"><b>SSSE3</b> é um <i>upgrade</i> ao <b>SSE3</b>, adicionando 16 novos códigos (<i>opcode</i>).</span></li> <li><span class="fs11lh1-5 ff1"><b>SSE4</b> é uma melhoria do padrão antecessor e adiciona um ponto de instrução do produto, diversas instruções adicionais (do tipo <i>integer</i>), uma instrução do tipo <i>popcnt</i>, entre outras.</span></li></ul><div><br></div><div><br></div><div><div><b class="fs11lh1-5 ff1">Intel Advanced Vector Extensions (AVX)</b></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O <b>Advanced Vector Extension</b> <b>(AVX)</b>, também conhecido como Sandy Bridge New Extensions, são extensões da arquitetura do conjunto de instruções x86 para microprocessadores da Intel e da AMD, propostas pela Intel em março de 2008 e primeiramente suportada pela Intel com o processador Sandy Bridge<sup>[2]</sup> no início de 2011, e mais tarde então pela AMD, com o processador Bulldozer, lançado no final do mesmo ano. O AVX fornece novos recursos, instruções e um novo esquema de codificação. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O AVX2 expande a maioria dos comandos inteiros para 256 bits &nbsp;e apresenta operações de multiplicação acumulada fundidas (FMA). O &nbsp;AVX-512 expande o AVX para o suporte de 512 bits usando uma nova &nbsp;codificação de prefixo EVEX, proposta pela Intel em julho de 2013 e suportada pela primeira vez por ela, com o processador Knights Landing, lançado em 2016.</span></div><div><br></div><div><span class="fs11lh1-5 ff1"><b>Índice</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><label for="toctogglecheckbox"></label></span></div><div> <ul> <li><span class="fs11lh1-5 ff1">1 AVX </span><ul> <li><span class="fs11lh1-5 ff1">1.1 Características</span></li> <li><span class="fs11lh1-5 ff1">1.2 Novas Instruções</span></li> <li><span class="fs11lh1-5 ff1">1.3 CPUs com AVX</span></li> <li><span class="fs11lh1-5 ff1">1.4 Suporte ao sistema operacional</span></li> </ul> </li> <li><span class="fs11lh1-5 ff1">2 AVX2 </span><ul> <li><span class="fs11lh1-5 ff1">2.1 Características</span></li> <li><span class="fs11lh1-5 ff1">2.2 Novas Instruções</span></li> <li><span class="fs11lh1-5 ff1">2.3 CPUs com AVX2</span></li> </ul> </li> <li><span class="fs11lh1-5 ff1">3 AVX-512 </span><ul> <li><span class="fs11lh1-5 ff1">3.1 CPUs com AVX-512</span></li> </ul> </li> <li><span class="fs11lh1-5 ff1">4 Aplicações </span><ul> <li><span class="fs11lh1-5 ff1">4.1 Softwares</span></li> </ul> </li> <li><span class="fs11lh1-5 ff1">5 Referências</span></li> </ul> </div><div> &nbsp;</div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>AVX</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Características</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O AVX utiliza dezesseis registradores YMM. Cada registrador YMM contém: </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <ul><li><span class="fs11lh1-5 ff1">Oito números de ponto flutuante de precisão única de 32 bits ou</span></li></ul> <ul><li><span class="fs11lh1-5 ff1">Quatro números de ponto flutuante de precisão dupla de 64 bits.</span></li></ul> <div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A largura do arquivo de registro SIMD &nbsp;é aumentada de 128 bits para 256 bits e renomeada de XMM0 – XMM7 para &nbsp;YMM0 – YMM7 (no modo x86-64, YMM0 – YMM15). Em processadores com o &nbsp;suporte a AVX, as instruções SSE (anteriormente operavam em &nbsp;registradores XMM de 128 bits) podem ser estendidas usando o prefixo VEX &nbsp;para operar nos 128 bits mais baixos dos registradores YMM. </span></div> <div> &nbsp;</div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Os registros YMM comparados aos registros XMM.</span></div> <div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Ele introduz um formato de instrução SIMD de três operandos, em que o &nbsp;registrador de destino é distinto dos dois operandos de origem. Por &nbsp;exemplo, uma instrução SSE usando a forma convencional de dois operandos &nbsp;a = a + b agora pode usar uma forma não destrutiva de três operandos c = &nbsp;a + b, preservando ambos os operandos fonte. O formato de três &nbsp;operandos do AVX é limitado às instruções com operandos SIMD (YMM) e não &nbsp;inclui instruções com registradores de propósito geral (por exemplo, &nbsp;EAX) (esse suporte aparecerá pela primeira vez no AVX2). &nbsp;O novo esquema de codificação VEX introduz um novo conjunto de prefixos &nbsp;de código que estende o espaço do opcode, permitindo que as instruções &nbsp;tenham mais de dois operandos e que os registradores vetoriais SIMD &nbsp;sejam maiores que 128 bits. O prefixo VEX também pode ser usado nas &nbsp;instruções herdadas do SSE, dando-lhes um formato de três operandos, e &nbsp;fazendo com que eles interajam mais eficientemente com as instruções do &nbsp;AVX, sem a necessidade de VZEROUPPER e ZEROALL. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As instruções do AVX suportam o SIMD de 128 bits e 256 bits. As &nbsp;versões de 128 bits podem ser úteis para melhorar o código antigo sem a &nbsp;necessidade de ampliar a vetorização, evitando assim a penalidade de ir &nbsp;do SSE para o AVX. Elas são mais rápidas em algumas implementações &nbsp;iniciais do AMD do AVX (este modo é conhecido como AVX-128). </span></div><div><span class="fs11lh1-5 ff1"><br></span></div> <div><span class="fs11lh1-5 ff1"><b>Novas Instruções</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Estas instruções são adicionais às que são extensões de 256 bits das instruções SSE de 128 bits e a maioria é utilizável em operandos de 128 e 256 bits. </span></div><div><br></div></div></section></div></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_7" class="imPageRow">
						
						</div>
						<div id="imCell_9" class=""  data-responsive-sequence-number="7"> <div id="imCellStyleGraphics_9"></div><div id="imCellStyleBorders_9"></div><div id="imTableObject_297_09">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTableObject_297_09_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<table data-minrequestedwidth="1422" data-computedwidth="1422" style="width: 1422px;"><tbody><tr><td style="width: 127px; height: 22px; margin-top: 0px; margin-left: 0px;" class="imVc"><div class="imTACenter"><span class="fs11lh1-5 ff1"><b>Instrução</b></span></div></td><td style="width: 1280px; height: 22px;" class="imVc"><div class="imTACenter"><span class="fs11lh1-5 ff1"><b>Descrição</b></span></div></td></tr><tr><td style="height: 66px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VBROADCASTSS</code>, <code>VBROADCASTSD</code>, <code>VBROADCASTF128</code> </span></div></td><td style="width: 1280px; height: 66px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Copia um operando de memória de 32 bits, 64 bits ou 128 bits para todos os elementos de um registrador vetorial XMM ou YMM. </span></div></td></tr><tr><td style="height: 45px; width: 127px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VINSERTF128</code> </span></div></td><td style="width: 1280px; height: 45px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Substitui a metade inferior ou a metade superior de um registrador YMM 
						de 256 bits pelo valor de um operando de origem de 128 bits. A outra 
						metade do destino não é alterada. </span></div></td></tr><tr><td style="height: 25px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VEXTRACTF128</code> </span></div></td><td style="width: 1280px; height: 25px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Extrai a metade inferior ou a metade superior de um registrador YMM de 
						256 bits e copia o valor para um operando de destino de 128 bits. </span></div></td></tr><tr><td style="height: 132px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VMASKMOVPS</code>, <code>VMASKMOVPD</code> </span></div></td><td style="width: 1280px; height: 132px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Lê qualquer número de elementos de um operando de memória vetorial SIMD 
						em um registrador de destino, deixando os elementos vetoriais restantes 
						não lidos e definindo os elementos correspondentes no registrador de 
						destino para zero. Grava qualquer número de elementos de um operando de 
						registrador vetorial SIMD em um operando de memória de vetores, deixando
						 os demais elementos do operando de memória inalterados. </span></div></td></tr><tr><td style="height: 51px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VPERMILPS</code>, <code>VPERMILPD</code> </span></div></td><td style="width: 1280px; height: 51px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Embaralha os elementos vetoriais de 32 bits ou 64 bits de um operando de
						 entrada. Estas são instruções de 256 bits em pista, o que significa que
						 elas operam em todos os 256 bits com dois shuffles de 128 bits 
						separados, de modo que não podem ser reproduzidos aleatoriamente nas 
						pistas de 128 bits. </span></div></td></tr><tr><td style="height: 38px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VPERM2F128</code> </span></div></td><td style="width: 1280px; height: 38px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Embaralha os quatro elementos de vetor de 128 bits de dois operandos de 
						fonte de 256 bits em um operando de destino de 256 bits, com uma 
						constante imediata como seletor </span></div></td></tr><tr><td style="height: 29px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VZEROALL</code> </span></div></td><td style="width: 1280px; height: 29px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Define todos os registradores YMM para zero e marca-os como não 
						utilizados. Usado ao alternar entre o uso de 128 bits e o uso de 256 
						bits. </span></div></td></tr><tr><td style="height: 22px; width: 127px;" class="imVc"><div><span class="fs11lh1-5 ff1"><code>VZEROUPPER</code> </span></div></td><td style="width: 1280px; height: 22px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><span class="fs11lh1-5 ff1">Ajusta a metade superior de todos os registradores YMM para zero. 
						Utilizado ao alternar entre o uso de 128 bits e o uso de 256 bits. </span></div></td></tr></tbody></table>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_8" class="imPageRow">
						
						</div>
						<div id="imCell_8" class=""  data-responsive-sequence-number="8"> <div id="imCellStyleGraphics_8"></div><div id="imCellStyleBorders_8"></div><div id="imTextObject_297_08">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_08_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>CPUs com AVX</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><b><span class="fs11lh1-5 ff1">Intel</span></b><span class="fs11lh1-5 ff1">:</span></div><div><ul><li><span class="fs11lh1-5 ff1">Processador Sandy Bridge (2011)</span></li><li><span class="fs11lh1-5 ff1">Processador Sandy Bridge E (2011)</span></li><li><span class="fs11lh1-5 ff1">Processador Ivy Bridge (2012)</span></li><li><span class="fs11lh1-5 ff1">Processador Ivy Bridge E (2013)</span></li><li><span class="fs11lh1-5 ff1">Processador Haswell (2013)</span></li><li><span class="fs11lh1-5 ff1">Processador Haswell E (2014)</span></li><li><span class="fs11lh1-5 ff1">Processador Broadwell (2014)</span></li><li><span class="fs11lh1-5 ff1">Processador Broadwell E (2016)</span></li><li><span class="fs11lh1-5 ff1">Processador Skylake (2015)</span></li><li><span class="fs11lh1-5 ff1">Processador Kaby Lake (ULV mobile - 2016) (desktop/mobile - 2017)</span></li><li><span class="fs11lh1-5 ff1">Processador Skylake-X (2017)</span></li><li><span class="fs11lh1-5 ff1">Processador Coffee Lake (2017)</span></li><li><span class="fs11lh1-5 ff1">Processador do Cannon Lake (microarquitetura), esperado para 2018</span></li><li><span class="fs11lh1-5 ff1">Processador Cascade Lake, esperado em 2018</span></li><li><span class="fs11lh1-5 ff1">Processador Ice Lake, esperado em 2018</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nem todas as CPUs das famílias listadas acima suportam o AVX. Geralmente, CPUs com a denominação "Core i3/i5/i7" as suportam, já as CPUs "Pentium" e "Celeron" não.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><b><span class="fs11lh1-5 ff1">AMD</span></b><span class="fs11lh1-5 ff1">:</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><ul><li><span class="fs11lh1-5 ff1">Processadores baseados em Jaguar e mais recentes</span></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Puma e mais recentes</span></li><li><span class="fs11lh1-5 ff1">Processadores "Equipamentos Pesados"</span><ul><li><span class="fs11lh1-5 ff1">Processadores baseados em Bulldozer (2011)</span></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Piledriver (2012)</span></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Steamroller (2014)</span></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Excavator e mais novos (2015)</span></li></ul></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Zen (2017)</span></li><li><span class="fs11lh1-5 ff1">Processadores baseados em Zen+ (2018)</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>Suporte ao sistema operacional</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O AVX adiciona um novo estado de registro através do arquivo de registro YMM de 256 bits, portanto, é necessário suporte explícito ao sistema operacional para salvar e restaurar adequadamente os registros expandidos do AVX entre os comutadores de contexto. As seguintes versões dos sistemas operacionais suportam o AVX:</span></div><div><ul><li><span class="fs11lh1-5 ff1">Apple OS X: Suporte para AVX adicionado na atualização 10.6.8 (Snow Leopard), lançado em 23 de junho de 2011.</span></li><li><span class="fs11lh1-5 ff1">O DragonFly BSD adicionou suporte no início de 2013.</span></li><li><span class="fs11lh1-5 ff1">FreeBSD em um patch enviado em 21 de janeiro de 2012, incluído na versão 9.1.</span></li><li><span class="fs11lh1-5 ff1">Linux: suportado desde a versão do kernel 2.6.30, lançado em 9 de junho de 2009.</span></li><li><span class="fs11lh1-5 ff1">O OpenBSD adicionou suporte em 21 de março de 2015.</span></li><li><span class="fs11lh1-5 ff1">Solaris 10 Update 10 e Solaris 11.</span></li><li><span class="fs11lh1-5 ff1">Windows: suportado no Windows 7 SP1 e no Windows Server 2008 R2 SP1, Windows 8, Windows 10.</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>AVX2</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Características<br></b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O</span><span class="fs11lh1-5 ff1"> </span><b><span class="fs11lh1-5 ff1">Advanced Vector Extensions 2 (AVX2)</span></b><span class="fs11lh1-5 ff1">, também conhecido como Haswell New Instructions</span><span class="fs11lh1-5 ff1">, é uma expansão do conjunto de instruções AVX introduzido na microarquitetura Haswell da Intel. O AVX2 faz as seguintes adições:</span></div><div><ul><li><span class="fs11lh1-5 ff1">Expansão da maioria das instruções SSE e AVX inteiras de vetores para 256 bits.</span></li></ul></div><div><ul><li><span class="fs11lh1-5 ff1">Manipulação de bits de uso geral de três operandos e multiplicação.</span></li></ul></div><div><ul><li><span class="fs11lh1-5 ff1">Reúne o suporte, permitindo que elementos vetoriais sejam carregados de locais &nbsp;de memória não contíguos.</span></li></ul></div><div><ul><li><span class="fs11lh1-5 ff1">DWORD- e QWORD-</span></li></ul></div><div><ul><li><span class="fs11lh1-5 ff1">Troca de vetores.</span></li></ul></div><div><ul><li><span class="fs11lh1-5 ff1">Suporte de multiplexação acumulada de três operandos (FMA3).</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>Novas Instruções</b></span></div><div><br></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_9" class="imPageRow">
						
						</div>
						<div id="imCell_10" class=""  data-responsive-sequence-number="9"> <div id="imCellStyleGraphics_10"></div><div id="imCellStyleBorders_10"></div><div id="imTableObject_297_10">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTableObject_297_10_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<table data-minrequestedwidth="1280" data-computedwidth="1280" style="width: 1280px;"><tbody><tr><td style="text-align: center; width: 118px; height: 22px; margin-top: 0px; margin-left: 0px;" class="imVc"><div><b class="fs11lh1-5 ff1">Instrução </b></div></td><td style="text-align: center; width: 1147px; height: 22px;" class="imVc"><div><b class="fs11lh1-5 ff1">Descrição </b></div></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VBROADCASTSS</code>, <code>VBROADCASTSD</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Copia um operando de registrador de 32 bits ou 64 bits para todos os 
						elementos de um registrador vetorial XMM ou YMM. Estas são versões de 
						registradores das mesmas instruções no AVX1. No entanto, não existe uma 
						versão de 128 bits, mas o mesmo efeito pode ser alcançado simplesmente 
						usando o VINSERTF128. <br></td></tr><tr><td style="height: 88px; width: 118px;" class="imVc"><code>VPBROADCASTB</code>, <code>VPBROADCASTW</code>, <code>VPBROADCASTD</code>, <code>VPBROADCASTQ</code> <br></td><td style="width: 1147px; height: 88px; margin-top: 0px; margin-left: 0px;" class="imVc">Copia um registrador inteiro de 8, 16, 32 ou 64 bits ou um operando de 
						memória para todos os elementos de um registrador vetorial XMM ou YMM. <br></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VBROADCASTI128</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Copia um operando de memória de 128 bits para todos os elementos de um registrador vetorial YMM. <br></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VINSERTI128</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Substitui a metade inferior ou a metade superior de um registrador YMM 
						de 256 bits pelo valor de um operando de origem de 128 bits. A outra 
						metade do destino não é alterada. <br></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VEXTRACTI128</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Extrai a metade inferior ou a metade superior de um registro YMM de 256 
						bits e copia o valor para um operando de destino de 128 bits. <br></td></tr><tr><td style="height: 88px; width: 118px; margin-top: 0px; margin-left: 0px;" class="imVc"><code>VGATHERDPD</code>, <code>VGATHERQPD</code>, <code>VGATHERDPS</code>, <code>VGATHERQPS</code> <br></td><td style="width: 1147px; height: 88px;" class="imVc">Reúne valores de ponto flutuante de precisão simples ou dupla usando índices e escala de 32 ou 64 bits. <br></td></tr><tr><td style="height: 88px; width: 118px;" class="imVc"><code>VPGATHERDD</code>, <code>VPGATHERDQ</code>, <code>VPGATHERQD</code>, <code>VPGATHERQQ</code> <br></td><td style="width: 1147px; height: 88px;" class="imVc">Reúne valores inteiros de 32 ou 64 bits usando índices e escala de 32 ou 64 bits. <br></td></tr><tr><td style="height: 63px; width: 118px;" class="imVc"><code>VPMASKMOVD</code>, <code>VPMASKMOVQ</code> <br></td><td style="width: 1147px; height: 63px; margin-top: 0px; margin-left: 0px;" class="imVc">Lê qualquer número de elementos de um operando de memória vetorial SIMD 
						em um registrador de destino, deixando os elementos vetoriais restantes 
						não lidos e definindo os elementos correspondentes no registrador de 
						destino para zero. Grava qualquer número de elementos de um operando de 
						registrador vetorial SIMD em um operando de memória de vetores, deixando
						 os demais elementos do operando de memória inalterados. <br></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VPERMPS</code>, <code>VPERMD</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Embaralha os oito elementos vetoriais de 32 bits de um operando fonte de
						 256 bits em um operando de destino de 256 bits, com um registrador ou 
						operando memória como seletor. <br></td></tr><tr><td style="height: 56px; width: 118px;" class="imVc"><code>VPERMPD</code>, <code>VPERMQ</code> <br></td><td style="width: 1147px; height: 56px;" class="imVc">Embaralha os quatro elementos de vetor de 64 bits de um operando de 
						fonte de 256 bits em um operando de destino de 256 bits, com um operando
						 de registro ou memória como seletor. <br></td></tr><tr><td style="height: 56px; width: 118px;" class="imVc"><code>VPERM2I128</code> <br></td><td style="width: 1147px; height: 56px;" class="imVc">Embaralha os quatro elementos de vetor de 128 bits de dois operandos de 
						fonte de 256 bits em um operando de destino de 256 bits, com uma 
						constante imediata como seletor. <br></td></tr><tr><td style="height: 56px; width: 118px;" class="imVc"><code>VPBLENDD</code> <br></td><td style="width: 1147px; height: 56px;" class="imVc">Versão imediata da palavra dupla das instruções PBLEND do SSE4. <br></td></tr><tr><td style="height: 56px; width: 118px;" class="imVc"><code>VPSLLVD</code>, <code>VPSLLVQ</code> <br></td><td style="width: 1147px; height: 56px;" class="imVc">Troca lógica. Permite deslocamentos variáveis em que cada elemento é deslocado de acordo com a entrada compactada. <br></td></tr><tr><td style="height: 58px; width: 118px;" class="imVc"><code>VPSRLVD</code>, <code>VPSRLVQ</code> <br></td><td style="width: 1147px; height: 58px;" class="imVc">Troca lógica. Permite deslocamentos variáveis em que cada elemento é deslocado de acordo com a entrada compactada. <br></td></tr><tr><td style="height: 60px; width: 118px;" class="imVc"><code>VPSRAVD</code> <br></td><td style="width: 1147px; height: 60px;" class="imVc">Troca lógica aritmética. Permite deslocamentos variáveis em que cada elemento é deslocado de acordo com a entrada compactada. <br></td></tr></tbody></table>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_10" class="imPageRow">
						
						</div>
						<div id="imCell_11" class=""  data-responsive-sequence-number="10"> <div id="imCellStyleGraphics_11"></div><div id="imCellStyleBorders_11"></div><div id="imTextObject_297_11">
							<div data-index="0"  class="text-tab-content grid-prop current-tab "  id="imTextObject_297_11_tab0" style="opacity: 1; ">
								<div class="text-inner">
									<div><br></div><div><div><span class="fs11lh1-5 ff1">CPUs com AVX2</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><b><span class="fs11lh1-5 ff1">Intel</span></b><span class="fs11lh1-5 ff1">:</span></div><div><ul><li><span class="fs11lh1-5 ff1">Processador Haswell (2013)</span></li><li><span class="fs11lh1-5 ff1">Processador Haswell E (2014)</span></li><li><span class="fs11lh1-5 ff1">Processador Broadwell (2014)</span></li><li><span class="fs11lh1-5 ff1">Processador Broadwell E (2016)</span></li><li><span class="fs11lh1-5 ff1">Processador Skylake (2015)</span></li><li><span class="fs11lh1-5 ff1">Processador Kaby Lake, (ULV mobile - 2016) (desktop/mobile - 2017)</span></li><li><span class="fs11lh1-5 ff1">Processador Skylake-X (2017)</span></li><li><span class="fs11lh1-5 ff1">Processador Coffee Lake (2017)</span></li><li><span class="fs11lh1-5 ff1">Processador Cannon Lake, esperado em 2018</span></li><li><span class="fs11lh1-5 ff1">Processador Cascade Lake, esperado em 2018</span></li><li><span class="fs11lh1-5 ff1">Processador Ice Lake, esperado em 2018</span></li></ul></div><div><b><span class="fs11lh1-5 ff1">AMD</span></b><span class="fs11lh1-5 ff1">:</span></div><div><ul><li><span class="fs11lh1-5 ff1">Processador Excavator e mais novos (2015)</span></li><li><span class="fs11lh1-5 ff1">Processador Zen (2017)</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>AVX-512</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O AVX-512</span><span class="fs11lh1-5 ff1"> </span><span class="fs11lh1-5 ff1">são extensões de 512 bits para as instruções SIMD de extensões de vetor avançadas de 256 bits para a arquitetura de conjunto de instruções x86 propostas pela Intel em julho de 2013 e programadas para serem suportadas em 2015 com o processador Knights Landing da Intel</span><span class="fs11lh1-5 ff1">.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A instrução AVX-512</span><span class="fs11lh1-5 ff1"> </span><span class="fs11lh1-5 ff1">é codificada com o novo prefixo EVEX. Ele permite 4 operandos, 7 novos registros opmask de 64 bits, modo de memória escalar com transmissão automática, controle de arredondamento explícito e modo de endereçamento de memória de deslocamento comprimido. A largura do arquivo de registro é aumentada para 512 bits e a contagem total de registros aumentada para 32 (registra ZMM0-ZMM31) no modo x86-64.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>CPUs com AVX-512</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><ul><li><span class="fs11lh1-5 ff1">Processadores Knights Landing (2016)</span></li><li><span class="fs11lh1-5 ff1">Processadores Knights Mill (2017)</span></li><li><span class="fs11lh1-5 ff1">Processadores Skylake-SP, Skylake-X (2017)</span></li><li><span class="fs11lh1-5 ff1">Processadores Cannon Lake (2018)</span></li><li><span class="fs11lh1-5 ff1">Processadores Ice Lake (2019)</span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>Aplicações</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O AVX é adequado para cálculos de ponto flutuante intensivo em aplicações multimídia, científicas e financeiras (o AVX2 adiciona suporte para operações inteiras).</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aumenta o paralelismo e o rendimento em cálculos SIMD de ponto flutuante, reduz a carga do registrador devido às instruções não destrutivas e melhora o desempenho do software Linux RAID (AVX2).</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>Softwares</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><ul><li><span class="fs11lh1-5 ff1">Blender - usa o AVX2 nos ciclos do mecanismo de renderização.</span></li><li><span class="fs11lh1-5 ff1">OpenSSL - usa funções criptográficas otimizadas para AVX e AVX2 desde a versão 1.0.2</span><span class="fs11lh1-5 ff1">.</span></li><li><span class="fs11lh1-5 ff1">Prime95 / MPrime, software usado para o GIMPS - começou a usar as instruções AVX desde a versão 27.x.</span></li><li><span class="fs11lh1-5 ff1">O dnetc, o software usado pela distributed.net, tem um núcleo AVX2 disponível para seu projeto RC5 e lançará em breve um para seu projeto OGR-28.</span></li><li><span class="fs11lh1-5 ff1">Einstein @ Home - usa o AVX em alguns de seus aplicativos distribuídos que buscam ondas gravitacionais.</span></li><li><span class="fs11lh1-5 ff1">RPCS3, emulador de código aberto para o PlayStation 3 - usa as instruções AVX2 e AVX-512 para emular jogos PS3.</span></li><li><span class="fs11lh1-5 ff1">Network Device Interface, um protocolo de vídeo / áudio IP desenvolvido pela NewTek para produção de transmissão ao vivo - usa AVX e AVX2 para aumentar o desempenho.</span></li></ul><div><span class="ff1"><span class="fs11lh1-5"><br></span></span></div></div></div><div><div><span class="fs11lh1-5 ff1"><b>3DNow!</b></span></div><div><br></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3DNow!</b> é uma extensão multimídia criada pela AMD para seus processadores, que teve início com o K6-2 em 1998. &nbsp;Em termos mais técnicos, é um acréscimo de instruções SIMD ao tradicional conjunto de instruções x86,
						 com o objetivo de melhor atender aos requisitos de processamento 
						vetorial de muitas aplicações predominantemente gráficas. Foi 
						originalmente desenvolvido como um aperfeiçoamento do conjunto de 
						instruções MMX, de modo a estender sua capacidade limitada a números inteiros também para ponto flutuante. Posteriormente, a Intel incorporaria instruções similares (porém incompatíveis) ao Pentium III, chamadas de SSE.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A AMD aperfeiçoou o conjunto de instruções ao longo do tempo. A primeira melhoria foi chamada simplesmente de <b>Enhanced 3DNow!</b> (3DNow! Aperfeiçoado), algumas vezes <b>Extended 3DNow!</b> (3DNow! Estendido), introduzida com os Athlons
						 de primeira geração, que acrescentou cerca de 19 novas instruções, a 
						maioria das quais para lidar com previsão de instrução, etc. Um fato 
						pouco conhecido é que essas novas adições continham uma implementação 
						parcial do SSE1. A segunda melhoria foi chamada de <b>3DNow! Profissional</b>, que foi introduzida com os processadores Athlon XP; &nbsp;essa versão &nbsp;basicamente integrava por completo a tecnologia SSE1 da Intel, combinando-a com a sua própria 3DNow!
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma vantagem da 3DNow! é poder somar ou mutiplicar os dois 
						números que estão armazenados no mesmo registro. Com a SSE, cada número 
						só pode ser combinado com um número na mesma posição em outro registro. 
						Essa habilidade, denominada <i>horizontal</i> pela Intel, é o principal acréscimo ao recém-lançado conjunto de instruções SSE3.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uma desvantagem da 3DNow! relativamente à SSE é que ela somente 
						armazena dois números num registro, diferentemente dos quatro na SSE. 
						Entretanto, as intruções 3DNow! podem ser geralmente executadas em menos
						 tempo que as instruções SSE.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3DNow! também compartilha os mesmos registros físicos do MMX, enquanto que o SSE tem seus próprios registros independentes. Como esses registros MMX e 3DNow! são também utilizados pelo padrão x87 FPU,
						 as instruções 3DNow! e x87 não podem ser utilizadas simultaneamente. 
						Todavia, por estarem referenciados ao FPU x87, os estados dos registros 
						da 3DNow! e MMX &nbsp;podem ser salvos e restaurados pelas tradicionais 
						instruções x87 FNSAVE e FRSTR. O uso das tradicionais instruções x87 
						significou que não foram necessárias quaisquer modificações no sistema operacional para dar suporte ao 3DNow!
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Em contraste, para salvar e restaurar o estado dos registros SSE,
						 foi necessário o uso das recém-introduzidas instruções FXSAVE e FXRSTR;
						 as instruções FX* são uma atualização das instruções <i>Salva</i> e <i>Restaura</i>
						 do antigo x87, porque estas poderiam salvar não apenas os estados do 
						registro SSE, como também os estados do registro x87 (o que significa, 
						portanto, que poderiam salvar também registros MMX e 3DNow!).
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O uso das instruções FX* exigiram que o processador entrasse numa
						 versão ligeiramente modificada do modo Protegido, chamada modo 
						Aperfeiçoado ("Enhanced mode"); a única diferença entre esses dois modos
						 foi que este último permitiu o uso de SSE (e, portanto, das instruções 
						FX*) e aquele desabilitou seu uso. Sistemas operacionais que dão suporte
						 à SSE entrariam no modo Aperfeiçoado, enquanto que aqueles 
						desconhecedores de sua existência entrariam somente no tradicional modo 
						Protegido. </span></div></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b>MMX</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><div><span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MMX</b> é uma tecnologia lançada como marca registrada pela Intel para os seus processadores Pentium MMX em 1997.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Esta tecnologia oferece um modelo de execução SIMD
						 simples, capaz de efectuar processamentos de dados inteiros, 
						empacotados em registros de 64 bits. Para isso, foram criados 8 novos 
						registros de 64 bits, mapeados sobre os registros de 80 bits já 
						existentes na unidade de ponto flutuante.
						</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As 47 novas instruções MMX permitem o tratamento em paralelo de 
						diversos itens de dados do tipo inteiro de 8, 16 ou 32 bits, empacotados
						 em grupos de 8, 4 ou 2 elementos. Para além desta possibilidade de 
						processamento em paralelo, a tecnologia MMX disponibiliza 
						funcionalidades orientadas para o processamento de dados multimédia, 
						como por exemplo a aritmética com saturação.
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<div><span class="fs11lh1-5 ff1"><b>Instruções MMX</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As 47 novas instruções MMX podem ser agrupadas em:
						</span></div><div><span class="fs11lh1-5 ff1"><br></span></div>
						<ul><li><span class="fs11lh1-5 ff1">instruções aritméticas</span></li>
						<li><span class="fs11lh1-5 ff1">instruções de comparação</span></li>
						<li><span class="fs11lh1-5 ff1">instruções de conversão</span></li>
						<li><span class="fs11lh1-5 ff1">instruções lógicas</span></li>
						<li><span class="fs11lh1-5 ff1">instruções de deslocamento</span></li>
						<li><span class="fs11lh1-5 ff1">instruções de transferência de dados</span></li>
						<li><span class="fs11lh1-5 ff1">instrução de inicialização (EMMS)</span></li></ul>
						<div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Todas as mnemónicas de instruções MMX (excepto a instrução EMMS) 
						começam pela letra P que indica processamento de dados empacotados. 
						Seguem-se caracteres que identificam a operação, o tipo de saturação e o
						 tipo de dados utilizado, como se indica na figura seguinte.</span></div></div><div><span class="fs11lh1-5 ff1"><br></span></div><div class="imTACenter"><span class="fs28lh1-5 ff1"><b>O que é FSB?</b></span></div><div class="imTACenter"><br></div><div class="imTALeft"><div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FSB é a sigla para <em>Front Side Bus,</em> que significa barramento 
						frontal, o responsável pela comunicação e transferência de dados entre a
						 CPU e a North Bridge da placa-mãe. Refere-se basicamente ao caminho de 
						comunicação do processador com o chipset da placa-mãe, sendo que 
						geralmente é utilizado quando existe menção ao clock externo do 
						processador.</div> <div> 
						</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Este barramento, juntamente com a memória cache, pode ser 
						acessado de maneira muito mais rápida do que a RAM do sistema. Sendo 
						assim, a largura de banda, ou o throughput teórico máximo do barramento 
						frontal, é especificado pelo produto da largura da vida de dados, além 
						da frequência de clock e a quantidade de transferências de dados 
						realizadas por ciclo de clock.</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;É a frequência do clock FSB que 
						irá determinar como será o desempenho da placa-mãe e do processador de 
						uma máquina. Isso, consequentemente, define se o desempenho de todo o 
						computador será bom ou se apresentará problemas. O motivo disso é que o 
						processamento precisa passar por várias etapas.</div><section> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Participe do nosso Grupo de Cupons e Descontos no Whatsapp e garanta sempre o menor preço em suas compras de produtos de tecnologia.</section> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A
						 quantidade de transferências realizadas por ciclo de clock é 
						determinada pela tecnologia utilizada. Na GTL+, por exemplo, é possível 
						notar uma transferência/ciclo, enquanto que na EV6 é possível duas 
						transferências/ciclo e a AGTL+ tem capacidade de realizar quatro 
						transferências/ciclo. Esta última é denominada pela Intel de Quad 
						Pumping.</div><div> 
						</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Muitos fabricantes 
						atualmente não anunciam a capacidade do FSB em megahertz (MHz) na 
						frequência do clock, mas sim em megatransfers por segundo (na sigla 
						MT/s). O motivo disso é que a frequência real é especificada pela 
						quantidade de transferências que podem ser feitas em cada ciclo de 
						clock.</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O ajuste da frequência do FSB é associado diretamente a 
						frequência de funcionamento da memória utilizada em um sistema. Por meio
						 do barramento de memoria, a RAM é conectada a North Bridge, assim como o
						 barramento frontal conecta a CPU e o North Bridge. Visto que 
						frequentemente ambos trabalham na mesma frequência, o aumento da 
						frequência do barramento frontal significa, na maioria dos casos, um 
						aumento de frequência da memória. Levando isso em consideração, é 
						importante notar que qualquer megahert acrescido no FSB terá um valor 
						muito alto para o processador e a memória RAM.</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nos sistemas 
						atuais é possível verificar a memória em 4:5 e em proporções idênticas. 
						Isso significa que a memória irá funcionar 4 ou 5 vezes mais veloz do 
						que o FSB. Um barramento de 133 MHz, por exemplo, pode operar a memória 
						em 166 MHz, fazendo parte de um processo denominado de sistema 
						"assíncrono".</div><div> </div><div>
						
						</div><div>
						
						</div> <div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configurar o Front Side Bus em níveis elevados demais pode 
						significar uma ameaça para o seu processador, pois a placa-mãe é quem 
						controla o FSB e ela possui um valor máximo estimado em 10% do que o FSB
						 suporta.</div><div><br></div><div><br></div><div><div class="imTACenter"><span class="fs28lh1-5 ff1"><b>O que é Hyper-threading ou SMT?</b></span></div><div class="imTACenter"><br></div>
							
							<div>
								</div><div><br></div>
						<div><div><br></div><div> &nbsp;<span class="fs11lh1-5 ff1"><b> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O multithreading simultâneo</b> ( <b>SMT</b> ) é uma técnica para melhorar a eficiência geral de CPUs superescalares com multithreading de hardware . &nbsp;O SMT permite vários encadeamentos independentes de execução para melhor utilizar os recursos fornecidos pelas arquiteturas de processador modernas.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O nome <i>multithreading</i>
						 é ambíguo, porque não apenas múltiplos threads podem ser executados 
						simultaneamente em um núcleo de CPU, mas também múltiplas tarefas (com 
						diferentes tabelas de páginas , diferentes segmentos de estados de tarefas , diferentes anéis de proteção , diferentes permissões de E / S , etc.). &nbsp;Embora rodando no mesmo núcleo, eles estão completamente separados um do outro. &nbsp;O multithreading é similar em conceito à multitarefa preemptiva, mas é implementado no nível de thread de execução em processadores superescalares modernos. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O multithread simultâneo (SMT) é uma das duas principais implementações de multithreading, a outra forma sendo multithreading temporal (também conhecida como super-threading). &nbsp;Em multithreading temporal, apenas um thread de instruções pode ser executado em qualquer estágio de pipeline de cada vez. &nbsp;Em multithreading simultâneo, instruções de mais de um thread podem ser executadas em qualquer estágio de pipeline de cada vez. 
						 Isso é feito sem grandes alterações na arquitetura básica do 
						processador: as principais adições necessárias são a capacidade de 
						buscar instruções de vários threads em um ciclo e um arquivo de registro
						 maior para armazenar dados de vários threads. &nbsp;O número de threads simultâneos pode ser decidido pelos projetistas de chips. 
						 Dois encadeamentos simultâneos por núcleo de CPU são comuns, mas alguns
						 processadores suportam até oito encadeamentos simultâneos por núcleo. </span></div><div><span class="fs11lh1-5 ff1"> 
						 Porque é realmente uma técnica de eficiência que inevitavelmente 
						aumenta o conflito em recursos compartilhados, medir ou concordar com 
						sua eficácia pode ser difícil. 
						 No entanto, a eficiência energética medida do SMT com cargas de 
						trabalho paralelas nativas e gerenciadas em implementações históricas de
						 130 nm a 32 nm Intel SMT ( hyper-threading
						 ) descobriu que em implementações de 45 nm e 32 nm, o SMT é 
						extremamente eficiente em energia, mesmo com processadores Atom inorder. Em sistemas modernos, o SMT explora de forma eficaz a simultaneidade com muito pouco poder dinâmico adicional. &nbsp;Ou seja, mesmo quando os ganhos de desempenho são mínimos, a economia no consumo de energia pode ser considerável.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Alguns pesquisadores mostraram que os encadeamentos extras podem ser 
						usados ​​para propagar de forma proativa um recurso compartilhado como 
						um cache, para melhorar o desempenho de outro encadeamento único, e 
						afirmar que isso mostra que o SMT não apenas aumenta a eficiência. &nbsp;Outros usam o SMT para fornecer computação redundante, para algum nível de detecção e recuperação de erros. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No entanto, na maioria dos casos atuais, o SMT envolve ocultar a 
						latência de memória, aumentar a eficiência e aumentar o rendimento de 
						cálculos por quantidade de hardware usado.</span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><b class="fs11lh1-5 ff1"> &nbsp;Taxonomia &nbsp;</b></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No design do processador, há duas maneiras de aumentar o paralelismo no
						 chip com menos requisitos de recursos: um é a técnica superescalar que 
						tenta explorar o paralelismo no nível de instrução (ILP); &nbsp;o outro é a abordagem multithreading que explora o TLP (thread level parallelism). </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Superscalar significa executar várias instruções ao mesmo tempo, 
						enquanto o TLP (Thread-Level Parallelism) executa instruções de vários 
						threads dentro de um chip ao mesmo tempo. &nbsp;Há muitas maneiras de suportar mais de um thread dentro de um chip, a saber: </span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><ul><li><span class="fs11lh1-5 ff1"> &nbsp;Multithreading Interleaved: problema intercalado de várias instruções de threads diferentes, também conhecido como multithreading temporal . 
						 Ele pode ser dividido em multithreading refinado ou multithreading de 
						granulação grossa, dependendo da freqüência de problemas intercalados. &nbsp;Multithreading refinado - como em um processador barril - fornece instruções para threads diferentes após cada ciclo, enquanto o multithreading de <b>granulação grosseira</b>
						 só alterna para emitir instruções de outro thread quando o thread em 
						execução atual causa alguns eventos de latência longos (como falha de 
						página etc. ). &nbsp;Multithreading de grão grosso é mais comum para menos alternância de contexto entre threads. &nbsp;Por exemplo, o processador Montecito da Intel usa multithreading de granulação grossa, enquanto o UltraSPARC T1 da Sun usa multithreading refinado. 
						 Para os processadores que têm apenas um pipeline por núcleo, o 
						multithreading intercalado é a única maneira possível, pois pode emitir 
						no máximo uma instrução por ciclo. </span></li><li><span class="fs11lh1-5 ff1"> &nbsp;Multithreading simultâneo (SMT): Emita várias instruções de vários segmentos em um ciclo. &nbsp;O processador deve ser superescalar para fazer isso. </span></li><li><span class="fs11lh1-5 ff1"> &nbsp;Multiprocessamento no nível de chip (CMP ou multicore ): integra dois ou mais processadores em um único chip, cada um executando threads de forma independente. </span></li><li><span class="fs11lh1-5 ff1"> &nbsp;Qualquer combinação de multithread / SMT / CMP. </span></li></ul></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O fator-chave para distingui-las é observar quantas instruções o 
						processador pode emitir em um ciclo e quantos encadeamentos de onde vêm 
						as instruções. 
						 Por exemplo, o UltraSPARC T1 da Sun Microsystems (conhecido como 
						"Niagara" até sua versão de 14 de novembro de 2005) é um processador 
						multicore combinado com multithreading fino em vez de multithreading 
						simultâneo porque cada núcleo só pode emitir uma instrução por vez. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Implementações históricas </b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Embora as CPUs com multithreads existam desde os anos 50, o 
						multithreading simultâneo foi pesquisado pela IBM em 1968 como parte do 
						projeto ACS-360. O primeiro grande microprocessador comercial desenvolvido com SMT foi o Alpha 21464 (EV8). &nbsp;Este microprocessador foi desenvolvido pela DEC
						 em coordenação com Dean Tullsen, da Universidade da Califórnia, em San 
						Diego, e Susan Eggers e Henry Levy, da Universidade de Washington. &nbsp;O microprocessador nunca foi lançado, uma vez que a linha Alpha de microprocessadores foi descontinuada pouco antes de a HP adquirir a Compaq, que por sua vez adquiriu a DEC . 
						 O trabalho de Dean Tullsen também foi usado para desenvolver as versões
						 Hyper-threading (Hyper-threading technology ou HTT) dos 
						microprocessadores Intel Pentium 4, como o "Northwood" e o "Prescott". </span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Implementações comerciais modernas </b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Intel Pentium 4
						 foi o primeiro processador de desktop moderno a implementar 
						multithreading simultâneo, a partir do modelo 3.06 GHz lançado em 2002, e
						 desde então introduzido em vários de seus processadores. &nbsp;A Intel chama a funcionalidade Hyper-threading e fornece um mecanismo SMT básico de dois segmentos. &nbsp;A Intel alega até 30% de melhoria de velocidade em comparação com um Pentium 4 não SMT idêntico. A melhoria de desempenho observada é muito dependente da aplicação; 
						 no entanto, ao executar dois programas que exigem atenção total do 
						processador, pode parecer que um ou ambos os programas diminuem um pouco
						 quando o Hyper-threading está ativado. Isso se deve ao sistema de reprodução do Pentium 4 que prendia valiosos recursos de execução, aumentando a contenção de recursos como largura de banda, caches, TLBs , entradas de buffers de reordenação
						 , equalização dos recursos do processador entre os dois programas, o 
						que adiciona uma variação. quantidade de tempo de execução. &nbsp;O núcleo do Pentium 4 Prescott ganhou uma fila de replay, o que reduz o tempo de execução necessário para o sistema de replay. &nbsp;Isso é suficiente para superar completamente o impacto no desempenho.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Os mais recentes projetos de arquitetura MIPS da Imagination Technologies incluem um sistema SMT conhecido como <i>"MIPS MT"</i>. O MIPS MT fornece elementos de processamento virtuais pesados ​​e microtemas de hardware mais leves. &nbsp;A RMI , uma startup baseada em Cupertino, é o primeiro fornecedor de MIPS a fornecer um SOC de processador baseado em oito núcleos, cada um dos quais executa quatro threads. &nbsp;Os encadeamentos podem ser executados no modo granular fino, onde um encadeamento diferente pode ser executado em cada ciclo. &nbsp;Os segmentos também podem receber prioridades. &nbsp;As CPUs MIPS da Imagination Technologies possuem dois threads SMT por núcleo. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Blue Gene / Q da IBM tem SMT de 4 vias. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O IBM POWER5
						 , anunciado em maio de 2004, vem como um módulo dual-chip (DCM) de dois
						 núcleos ou MCM (quad-core ou oct-core multi-chip module), com cada 
						núcleo incluindo um mecanismo SMT de dois segmentos. 
						 A implementação da IBM é mais sofisticada do que as anteriores, porque 
						pode atribuir uma prioridade diferente aos vários encadeamentos, é mais 
						refinada e o mecanismo SMT pode ser ativado e desativado dinamicamente, 
						para melhor executar essas cargas de trabalho onde um processador SMT 
						não aumenta o desempenho. &nbsp;Esta é a segunda implementação da IBM de multithreading de hardware geralmente disponível. 
						 Em 2010, a IBM lançou sistemas baseados no processador POWER7 com oito 
						núcleos, cada um com quatro Threads Inteligentes Simultâneos. 
						 Isso alterna o modo de encadeamento entre um encadeamento, dois 
						encadeamentos ou quatro encadeamentos, dependendo do número de 
						encadeamentos do processo que estão sendo agendados no momento. &nbsp;Isso otimiza o uso do núcleo para tempo de resposta mínimo ou throughput máximo. &nbsp;O IBM POWER8 possui 8 encadeamentos simultâneos inteligentes por núcleo (SMT8). </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O IBM z13 possui dois encadeamentos por núcleo (SMT-2). </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Embora muitas pessoas tenham informado que o UltraSPARC T1 da Sun Microsystems (conhecido como <i>"Niagara"</i> até 14 de novembro de 2005) e o agora extinto processador <i>" Rock "</i> (originalmente anunciado em 2005, mas após muitos atrasos cancelados em 2009) são implementações do SPARC focado quase inteiramente na exploração de técnicas SMT e CMP, o Niagara não está realmente usando o SMT. &nbsp;A Sun se refere a essas abordagens combinadas como "CMT" e o conceito geral como "Throughput Computing". &nbsp;O Niagara tem oito núcleos, mas cada núcleo tem apenas um pipeline, então, na verdade, ele usa multithreading refinado. 
						 Ao contrário do SMT, onde as instruções de vários threads compartilham a
						 janela do problema a cada ciclo, o processador usa uma política de 
						round robin para emitir instruções a partir do próximo thread ativo em 
						cada ciclo. &nbsp;Isso faz com que seja mais semelhante a um processador barril. &nbsp;O processador Rock da Sun Microsystems é diferente, tem núcleos mais complexos que possuem mais de um pipeline. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Oracle Corporation
						 Sparc T3 possui oito threads finos por núcleo, o Sparc T4, o Sparc T5, o
						 Sparc M5, o M6 e o ​​M7 possuem oito threads finos por núcleo, dos 
						quais dois podem ser executados simultaneamente. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Fujitsu Sparc64 VI possui Sparc VII vertical multirrescrito de granulação grossa e o mais novo possui SMT bidirecional. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Intel Itanium
						 Montecito usou multithreading de granulação grossa e Tukwila e mais 
						recentes usam o 2-way SMT (com multithreading de domínio dual). </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;O Intel Xeon Phi
						 possui um SMT de 4 vias (com multiplexação multiplexada no tempo) com 
						encadeamentos baseados em hardware que não podem ser desativados, ao 
						contrário do Hyperthreading normal. O Intel Atom
						 , lançado em 2008, é o primeiro produto da Intel a apresentar o SMT 
						bidirecional (comercializado como Hyper-Threading) sem suportar 
						reordenamento de instruções, execução especulativa ou renomeação de 
						registradores. &nbsp;A Intel reintroduziu o Hyper-Threading com a microarquitetura Nehalem , após sua ausência na microarquitetura Core. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A microarquitetura AMD Bulldozer FlexFPU
						 e o cache compartilhado L2 são multithreaded, mas os núcleos inteiros 
						no módulo são de thread único, portanto, é apenas uma implementação 
						parcial do SMT.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A microarquitetura AMD Zen possui 2 vias SMT. </span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A arquitetura VISC usa a <i>Virtual Software Layer</i> (camada de tradução) para enviar um único encadeamento de instruções para o <i>Global Front End,</i> que divide instruções em encadeamentos de <i>hardware virtual</i> que são então despachados para separar núcleos virtuais. &nbsp;Esses núcleos virtuais podem, então, enviá-los para os recursos disponíveis em qualquer um dos núcleos físicos. 
						 Diversos núcleos virtuais podem enviar encadeamentos para o buffer de 
						reordenamento de um único núcleo físico, que pode dividir instruções e 
						dados parciais de vários encadeamentos por meio das portas de execução 
						ao mesmo tempo. &nbsp;Cada núcleo virtual acompanha a posição da saída relativa. 
						 Essa forma de multithreading pode aumentar o desempenho de thread 
						único, permitindo que um único thread use todos os recursos da CPU. 
						 A alocação de recursos é dinâmica em um nível de latência de ciclo 
						quase único (1-4 ciclos dependendo da mudança na alocação dependendo das
						 necessidades individuais da aplicação. Portanto, se dois núcleos 
						virtuais estiverem competindo por recursos, existem algoritmos 
						apropriados para determinar quais recursos devem ser alocados onde. </span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"><b> &nbsp;Desvantagens &nbsp;</b></span></div><div><span class="fs11lh1-5 ff1"><br></span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dependendo do design e da arquitetura do processador, o multithread 
						simultâneo pode diminuir o desempenho se qualquer um dos recursos 
						compartilhados forem gargalos de desempenho. Os críticos argumentam que é um fardo considerável colocar os 
						desenvolvedores de software para testar se o multithreading simultâneo é
						 bom ou ruim para sua aplicação em várias situações e inserir uma lógica
						 extra para desligá-lo se ele diminuir o desempenho. &nbsp;Os sistemas operacionais atuais não possuem chamadas API convenientes para essa finalidade e para impedir que processos com prioridades diferentes obtenham recursos uns dos outros.</span></div><div><span class="fs11lh1-5 ff1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Há também uma preocupação de segurança com certas implementações simultâneas de multithreading. &nbsp;O hyperthreading da Intel em processadores baseados em NetBurst tem uma vulnerabilidade através da qual é possível que um aplicativo roube uma chave criptográfica de outro aplicativo em execução no mesmo processador, monitorando seu uso de cache. Há também sofisticadas explorações de aprendizado de máquina para implementação de HT que foram explicadas no Black Hat 2018.</span></div></div></div><div><span class="ff1"><span class="fs11lh1-5"><br></span></span></div><div><span class="ff1"><span class="fs11lh1-5"><br></span></span></div></div>
								</div>
							</div>
						
						</div>
						</div><div id="imPageRow_11" class="imPageRow">
						
						</div>
						<div id="imPageRow_12" class="imPageRow">
						
						</div>
						<div id="imCell_6" class=""  data-responsive-sequence-number="11"> <div id="imCellStyleGraphics_6"></div><div id="imCellStyleBorders_6"></div><div id="GuestBookObject_297_06" style="height: 650px; overflow-y: auto; overflow-x: hidden;">
						<div id="fb-root"></div><div class="fb-comments" data-href="http://192.168.42.178:8080/processadores.html" data-numposts="10" data-width="100%" data-colorscheme="light"></div><script>$(".fb-comments").attr("data-href", location.href);(function(d, s, id) {var js, fjs = d.getElementsByTagName(s)[0];if (d.getElementById(id)) return;js = d.createElement(s); js.id = id;js.src = "//connect.facebook.net/pt_BR/sdk.js#xfbml=1&version=v2.6";fjs.parentNode.insertBefore(js, fjs);}(document, 'script', 'facebook-jssdk'));</script></div>
						</div>
					</main>
					<footer id="imFooter">
						<div id="imFooterObjects"></div>
					</footer>
				</div>
				<span class="imHidden"><a href="#imGoToCont" title="Ler esta página novamente">Voltar para o conteúdo</a></span>
			</div>
		</div>
		
		<noscript class="imNoScript"><div class="alert alert-red">Para usar este site você deve habilitar o JavaScript.</div></noscript>
	</body>
</html>
